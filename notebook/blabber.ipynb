{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blabber Cleaning\n",
    "#### (By: Mark Ehab Aziz)\n",
    "#### (Built Under: Python 3.11.4)\n",
    "Filtering out and cleaning text data.\n",
    "As tasked inside the 'to do.txt'.\n",
    "\n",
    "Ensure the presence of nltk package using `pip install nltk`.\n",
    "\n",
    "Following usage of nltk should not require further dependencies than the basic install and stopwords.\n",
    "\n",
    "If anything; Ensure presence of `nltk`, the download for stopwords is within the cells and will download automatically should it not detect any instance of predownloaded stopwords for itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd                         # Loading Data\n",
    "import nltk                                 # Required to download stopwords set\n",
    "from nltk.corpus import stopwords           # Load Stopwords\n",
    "from nltk.tokenize import regexp_tokenize   # To Tokenize words with Regex Expressions\n",
    "from nltk.stem import PorterStemmer         # Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into environment\n",
    "# Using two methods (As stated in my previous projects)\n",
    "# 1. Path working within my git repo\n",
    "blab = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# 2. Path when data is within the same folder\n",
    "#blab = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Using `.head(n)` to show the first $n^{th}$ rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining n rows to see\n",
    "n = 5\n",
    "\n",
    "# Showing head\n",
    "blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated by our todo list, we are only tasked with cleaning of the text, so we'll be focusing on `comment_text`.\n",
    "\n",
    "Referring to our todo list once again, we will be dropping `id`, `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`; as we are not concerned with classifying the sentiment or the meaning behind any of the comments.\n",
    "\n",
    "Reminder for what to be done:\n",
    "- Read Text\n",
    "- Clean Text (Capitalisation, punctuation)\n",
    "- Remove Stop Words\n",
    "- Tokenization\n",
    "- Stemming\n",
    "\n",
    "Under no aforementioned task will we be using the columns I have mentioned to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation\\r\\nWhy the edits made under my use...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining list of columns to be dropped\n",
    "col_droppable = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Dropping\n",
    "txt_blab = blab.drop(columns = col_droppable)\n",
    "\n",
    "# Viewing\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation  Why the edits made under my usern...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"  More  I can't make any real suggestions on ...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing '\\n' '\\r' '\\t' from every line\n",
    "txt_blab.replace(r'[\\r\\n\\t]', ' ', regex = True, inplace=True)\n",
    "\n",
    "# As noted, there are no escape characters for spaces, as new line or tab\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Above Sentences\n",
    "Using the NLTK library for Python; will be copy-pasting or creating patterns that are enough to extract words, starting with either upper or lower case letters.\n",
    "\n",
    "This may violate the order of operations specified in the ToDo list, as cleaning data preceeds tokenization, but `regexp_tokenize()` takes care of both steps anyway, through just matching what is specified within the regex, as only 'Latin Alphabet' ranges are specified (`A-Za-z`), it will automatically unmatch any special character or non-alphabet character, ignores punctuation as well.\n",
    "\n",
    "Will also be removing the URLs as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regex patterns\n",
    "# Match words starting with Uppercase letters\n",
    "upper_words = r\"([A-Z])\\w+\"\n",
    "\n",
    "# Match Words that start with either Upper/lowercase letters\n",
    "upper_lower_words = r\"[A-Za-z]\\w+\"\n",
    "\n",
    "# Match URLs\n",
    "url_pattern = r\"(http|ftp|https):\\/\\/([\\w+?\\.\\w+])+([a-zA-Z0-9\\~\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)_\\-\\=\\+\\\\\\/\\?\\.\\:\\;\\'\\,]*)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation  Why the edits made under my usern...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"  More  I can't make any real suggestions on ...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing URLs (Standard URL Scheme, There still exist instances\n",
    "# of just 'https' or 'http' randomly written, they will just be\n",
    "# treated like normal words and tokenized as the rest)\n",
    "txt_blab.replace(url_pattern, '', regex = True, inplace = True)\n",
    "\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Iterating over each row of the given textual data, accessing as a string instead of a usual row in order to yield the full entry.\n",
    "\n",
    "Using regex to tokenize words by matching pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a list of tokens, to hold tokens of each entry\n",
    "# Probably better to use a dictionary if we care about count (?)\n",
    "# Still have to access every token and change to lower (Taken care of in flat list)\n",
    "token_per_row = []\n",
    "\n",
    "# Start and finish indecies of iterator\n",
    "# Bound to become the length of the file eventually\n",
    "for i in range(50):\n",
    "    # Grab string fully from dataframe\n",
    "    line = txt_blab.iloc[i,0]\n",
    "\n",
    "    # Append list of tokens\n",
    "    # 2D list of lists; each containing tokens of each row\n",
    "    token_per_row.append(regexp_tokenize(line, upper_lower_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 2D List of Lists\n",
    "# n^2 operation but still gets the job done\n",
    "# Would be better to flatten as soon as\n",
    "# the tokens are fresh out the tokenizer\n",
    "def flatten(list_o_lists):\n",
    "    # init flat list\n",
    "    flat = []\n",
    "\n",
    "    # Loop over every list within the list\n",
    "    for sublist in list_o_lists:\n",
    "        # Loop over every token within the sublist\n",
    "        # being iterated on\n",
    "        for token in sublist:\n",
    "            # Append token to flat list\n",
    "            flat.append(token)\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 'vandalisms', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'don', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'retired', 'now', 'aww', 'He', 'matches', 'this', 'background', 'colour', 'seemingly', 'stuck', 'with', 'Thanks', 'talk', 'January', 'UTC', 'Hey', 'man', 'really', 'not', 'trying', 'to', 'edit', 'war', 'It', 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', 'He', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info', 'More', 'can', 'make', 'any', 'real', 'suggestions', 'on', 'improvement', 'wondered', 'if', 'the', 'section', 'statistics', 'should', 'be', 'later', 'on', 'or', 'subsection', 'of', 'types', 'of', 'accidents', 'think', 'the', 'references', 'may', 'need', 'tidying', 'so', 'that', 'they', 'are', 'all', 'in', 'the', 'exact', 'same', 'format', 'ie', 'date', 'format', 'etc', 'can', 'do', 'that', 'later', 'on', 'if', 'no', 'one', 'else', 'does', 'first', 'if', 'you', 'have', 'any', 'preferences', 'for', 'formatting', 'style', 'on', 'references', 'or', 'want', 'to', 'do', 'it', 'yourself', 'please', 'let', 'me', 'know', 'There', 'appears', 'to', 'be', 'backlog', 'on', 'articles', 'for', 'review', 'so', 'guess', 'there', 'may', 'be', 'delay', 'until', 'reviewer', 'turns', 'up', 'It', 'listed', 'in', 'the', 'relevant', 'form', 'eg', 'Wikipedia', 'Good_article_nominations', 'Transport', 'You', 'sir', 'are', 'my', 'hero', 'Any', 'chance', 'you', 'remember', 'what', 'page', 'that', 'on', 'Congratulations', 'from', 'me', 'as', 'well', 'use', 'the', 'tools', 'well', 'talk', 'COCKSUCKER', 'BEFORE', 'YOU', 'PISS', 'AROUND', 'ON', 'MY', 'WORK', 'Your', 'vandalism', 'to', 'the', 'Matt', 'Shirvington', 'article', 'has', 'been', 'reverted', 'Please', 'don', 'do', 'it', 'again', 'or', 'you', 'will', 'be', 'banned', 'Sorry', 'if', 'the', 'word', 'nonsense', 'was', 'offensive', 'to', 'you', 'Anyway', 'not', 'intending', 'to', 'write', 'anything', 'in', 'the', 'article', 'wow', 'they', 'would', 'jump', 'on', 'me', 'for', 'vandalism', 'merely', 'requesting', 'that', 'it', 'be', 'more', 'encyclopedic', 'so', 'one', 'can', 'use', 'it', 'for', 'school', 'as', 'reference', 'have', 'been', 'to', 'the', 'selective', 'breeding', 'page', 'but', 'it', 'almost', 'stub', 'It', 'points', 'to', 'animal', 'breeding', 'which', 'is', 'short', 'messy', 'article', 'that', 'gives', 'you', 'no', 'info', 'There', 'must', 'be', 'someone', 'around', 'with', 'expertise', 'in', 'eugenics', 'alignment', 'on', 'this', 'subject', 'and', 'which', 'are', 'contrary', 'to', 'those', 'of', 'DuLithgow', 'Fair', 'use', 'rationale', 'for', 'Image', 'Wonju', 'jpg', 'Thanks', 'for', 'uploading', 'Image', 'Wonju', 'jpg', 'notice', 'the', 'image', 'page', 'specifies', 'that', 'the', 'image', 'is', 'being', 'used', 'under', 'fair', 'use', 'but', 'there', 'is', 'no', 'explanation', 'or', 'rationale', 'as', 'to', 'why', 'its', 'use', 'in', 'Wikipedia', 'articles', 'constitutes', 'fair', 'use', 'In', 'addition', 'to', 'the', 'boilerplate', 'fair', 'use', 'template', 'you', 'must', 'also', 'write', 'out', 'on', 'the', 'image', 'description', 'page', 'specific', 'explanation', 'or', 'rationale', 'for', 'why', 'using', 'this', 'image', 'in', 'each', 'article', 'is', 'consistent', 'with', 'fair', 'use', 'Please', 'go', 'to', 'the', 'image', 'description', 'page', 'and', 'edit', 'it', 'to', 'include', 'fair', 'use', 'rationale', 'If', 'you', 'have', 'uploaded', 'other', 'fair', 'use', 'media', 'consider', 'checking', 'that', 'you', 'have', 'specified', 'the', 'fair', 'use', 'rationale', 'on', 'those', 'pages', 'too', 'You', 'can', 'find', 'list', 'of', 'image', 'pages', 'you', 'have', 'edited', 'by', 'clicking', 'on', 'the', 'my', 'contributions', 'link', 'it', 'is', 'located', 'at', 'the', 'very', 'top', 'of', 'any', 'Wikipedia', 'page', 'when', 'you', 'are', 'logged', 'in', 'and', 'then', 'selecting', 'Image', 'from', 'the', 'dropdown', 'box', 'Note', 'that', 'any', 'fair', 'use', 'images', 'uploaded', 'after', 'May', 'and', 'lacking', 'such', 'an', 'explanation', 'will', 'be', 'deleted', 'one', 'week', 'after', 'they', 'have', 'been', 'uploaded', 'as', 'described', 'on', 'criteria', 'for', 'speedy', 'deletion', 'If', 'you', 'have', 'any', 'questions', 'please', 'ask', 'them', 'at', 'the', 'Media', 'copyright', 'questions', 'page', 'Thank', 'you', 'talk', 'contribs', 'Unspecified', 'source', 'for', 'Image', 'Wonju', 'jpg', 'Thanks', 'for', 'uploading', 'Image', 'Wonju', 'jpg', 'noticed', 'that', 'the', 'file', 'description', 'page', 'currently', 'doesn', 'specify', 'who', 'created', 'the', 'content', 'so', 'the', 'copyright', 'status', 'is', 'unclear', 'If', 'you', 'did', 'not', 'create', 'this', 'file', 'yourself', 'then', 'you', 'will', 'need', 'to', 'specify', 'the', 'owner', 'of', 'the', 'copyright', 'If', 'you', 'obtained', 'it', 'from', 'website', 'then', 'link', 'to', 'the', 'website', 'from', 'which', 'it', 'was', 'taken', 'together', 'with', 'restatement', 'of', 'that', 'website', 'terms', 'of', 'use', 'of', 'its', 'content', 'is', 'usually', 'sufficient', 'information', 'However', 'if', 'the', 'copyright', 'holder', 'is', 'different', 'from', 'the', 'website', 'publisher', 'then', 'their', 'copyright', 'should', 'also', 'be', 'acknowledged', 'As', 'well', 'as', 'adding', 'the', 'source', 'please', 'add', 'proper', 'copyright', 'licensing', 'tag', 'if', 'the', 'file', 'doesn', 'have', 'one', 'already', 'If', 'you', 'created', 'took', 'the', 'picture', 'audio', 'or', 'video', 'then', 'the', 'tag', 'can', 'be', 'used', 'to', 'release', 'it', 'under', 'the', 'GFDL', 'If', 'you', 'believe', 'the', 'media', 'meets', 'the', 'criteria', 'at', 'Wikipedia', 'Fair', 'use', 'use', 'tag', 'such', 'as', 'or', 'one', 'of', 'the', 'other', 'tags', 'listed', 'at', 'Wikipedia', 'Image', 'copyright', 'tags', 'Fair', 'use', 'See', 'Wikipedia', 'Image', 'copyright', 'tags', 'for', 'the', 'full', 'list', 'of', 'copyright', 'tags', 'that', 'you', 'can', 'use', 'If', 'you', 'have', 'uploaded', 'other', 'files', 'consider', 'checking', 'that', 'you', 'have', 'specified', 'their', 'source', 'and', 'tagged', 'them', 'too', 'You', 'can', 'find', 'list', 'of', 'files', 'you', 'have', 'uploaded', 'by', 'following', 'this', 'link', 'Unsourced', 'and', 'untagged', 'images', 'may', 'be', 'deleted', 'one', 'week', 'after', 'they', 'have', 'been', 'tagged', 'as', 'described', 'on', 'criteria', 'for', 'speedy', 'deletion', 'If', 'the', 'image', 'is', 'copyrighted', 'under', 'non', 'free', 'license', 'per', 'Wikipedia', 'Fair', 'use', 'then', 'the', 'image', 'will', 'be', 'deleted', 'hours', 'after', 'If', 'you', 'have', 'any', 'questions', 'please', 'ask', 'them', 'at', 'the', 'Media', 'copyright', 'questions', 'page', 'Thank', 'you', 'talk', 'contribs', 'bbq', 'be', 'man', 'and', 'lets', 'discuss', 'it', 'maybe', 'over', 'the', 'phone', 'Hey', 'what', 'is', 'it', 'talk', 'What', 'is', 'it', 'an', 'exclusive', 'group', 'of', 'some', 'WP', 'TALIBANS', 'who', 'are', 'good', 'at', 'destroying', 'self', 'appointed', 'purist', 'who', 'GANG', 'UP', 'any', 'one', 'who', 'asks', 'them', 'questions', 'abt', 'their', 'ANTI', 'SOCIAL', 'and', 'DESTRUCTIVE', 'non', 'contribution', 'at', 'WP', 'Ask', 'Sityush', 'to', 'clean', 'up', 'his', 'behavior', 'than', 'issue', 'me', 'nonsensical', 'warnings', 'Before', 'you', 'start', 'throwing', 'accusations', 'and', 'warnings', 'at', 'me', 'lets', 'review', 'the', 'edit', 'itself', 'making', 'ad', 'hominem', 'attacks', 'isn', 'going', 'to', 'strengthen', 'your', 'argument', 'it', 'will', 'merely', 'make', 'it', 'look', 'like', 'you', 'are', 'abusing', 'your', 'power', 'as', 'an', 'admin', 'Now', 'the', 'edit', 'itself', 'is', 'relevant', 'this', 'is', 'probably', 'the', 'single', 'most', 'talked', 'about', 'event', 'int', 'he', 'news', 'as', 'of', 'late', 'His', 'absence', 'is', 'notable', 'since', 'he', 'is', 'the', 'only', 'living', 'ex', 'president', 'who', 'did', 'not', 'attend', 'That', 'certainly', 'more', 'notable', 'than', 'his', 'dedicating', 'an', 'aircracft', 'carrier', 'intend', 'to', 'revert', 'this', 'edit', 'in', 'hopes', 'of', 'attracting', 'the', 'attention', 'of', 'an', 'admin', 'that', 'is', 'willing', 'to', 'look', 'at', 'the', 'issue', 'itself', 'and', 'not', 'throw', 'accusations', 'around', 'quite', 'so', 'liberally', 'Perhaps', 'if', 'you', 'achieve', 'level', 'of', 'civility', 'where', 'you', 'can', 'do', 'this', 'we', 'can', 'have', 'rational', 'discussion', 'on', 'the', 'topic', 'and', 'resolve', 'the', 'matter', 'peacefully', 'Oh', 'and', 'the', 'girl', 'above', 'started', 'her', 'arguments', 'with', 'me', 'She', 'stuck', 'her', 'nose', 'where', 'it', 'doesn', 'belong', 'believe', 'the', 'argument', 'was', 'between', 'me', 'and', 'Yvesnimmo', 'But', 'like', 'said', 'the', 'situation', 'was', 'settled', 'and', 'apologized', 'Thanks', 'Juelz', 'Santanas', 'Age', 'In', 'Juelz', 'Santana', 'was', 'years', 'old', 'then', 'came', 'February', 'th', 'which', 'makes', 'Juelz', 'turn', 'making', 'songs', 'with', 'The', 'Diplomats', 'The', 'third', 'neff', 'to', 'be', 'signed', 'to', 'Cam', 'label', 'under', 'Roc', 'Fella', 'In', 'he', 'was', 'years', 'old', 'coming', 'out', 'with', 'his', 'own', 'singles', 'Santana', 'Town', 'and', 'Down', 'So', 'yes', 'he', 'is', 'born', 'in', 'He', 'really', 'is', 'how', 'could', 'he', 'be', 'older', 'then', 'Lloyd', 'Banks', 'And', 'how', 'could', 'he', 'be', 'when', 'his', 'birthday', 'passed', 'The', 'homie', 'neff', 'is', 'years', 'old', 'Juelz', 'death', 'god', 'forbid', 'if', 'your', 'thinking', 'about', 'that', 'equals', 'Go', 'to', 'your', 'caculator', 'and', 'stop', 'changing', 'his', 'year', 'of', 'birth', 'My', 'god', 'Bye', 'Don', 'look', 'come', 'or', 'think', 'of', 'comming', 'back', 'Tosser', 'REDIRECT', 'Talk', 'Voydan', 'Pop', 'Georgiev', 'Chernodrinski', 'The', 'Mitsurugi', 'point', 'made', 'no', 'sense', 'why', 'not', 'argue', 'to', 'include', 'Hindi', 'on', 'Ryo', 'Sakazaki', 'page', 'to', 'include', 'more', 'information', 'Don', 'mean', 'to', 'bother', 'you', 'see', 'that', 'you', 're', 'writing', 'something', 'regarding', 'removing', 'anything', 'posted', 'here', 'and', 'if', 'you', 'do', 'oh', 'well', 'but', 'if', 'not', 'and', 'you', 'can', 'acctually', 'discuss', 'this', 'with', 'me', 'then', 'even', 'better', 'like', 'to', 'ask', 'you', 'to', 'take', 'closer', 'look', 'at', 'the', 'Premature', 'wrestling', 'deaths', 'catagory', 'and', 'the', 'men', 'listed', 'in', 'it', 'surely', 'these', 'men', 'belong', 'together', 'in', 'some', 'catagory', 'Is', 'there', 'anything', 'that', 'you', 'think', 'we', 'can', 'do', 'with', 'the', 'catagory', 'besides', 'delting', 'it', 'Regarding', 'your', 'recent', 'edits', 'Once', 'again', 'please', 'read', 'WP', 'FILMPLOT', 'before', 'editing', 'any', 'more', 'film', 'articles', 'Your', 'edits', 'are', 'simply', 'not', 'good', 'with', 'entirely', 'too', 'many', 'unnecessary', 'details', 'and', 'very', 'bad', 'writing', 'Please', 'stop', 'before', 'you', 'do', 'further', 'damage', 'The', 'Good', 'to', 'know', 'About', 'me', 'yeah', 'studying', 'now', 'Deepu', 'Snowflakes', 'are', 'NOT', 'always', 'symmetrical', 'Under', 'Geometry', 'it', 'is', 'stated', 'that', 'snowflake', 'always', 'has', 'six', 'symmetric', 'arms', 'This', 'assertion', 'is', 'simply', 'not', 'true', 'According', 'to', 'Kenneth', 'Libbrecht', 'The', 'rather', 'unattractive', 'irregular', 'crystals', 'are', 'by', 'far', 'the', 'most', 'common', 'variety', 'Someone', 'really', 'need', 'to', 'take', 'look', 'at', 'his', 'site', 'and', 'get', 'FACTS', 'off', 'of', 'it', 'because', 'still', 'see', 'decent', 'number', 'of', 'falsities', 'on', 'this', 'page', 'forgive', 'me', 'Im', 'new', 'at', 'this', 'and', 'dont', 'want', 'to', 'edit', 'anything', 'The', 'Signpost', 'September', 'Read', 'this', 'Signpost', 'in', 'full', 'Single', 'page', 'Unsubscribe', 'Re', 'considering', 'st', 'paragraph', 'edit', 'don', 'understand', 'the', 'reasons', 'for', 'recent', 'edit', 'of', 'this', 'article', 'not', 'that', 'sure', 'that', 'the', 'data', 'are', 'necessarily', 'wrong', 'Rather', 'persuaded', 'that', 'the', 'strategy', 'of', 'introducing', 'academic', 'honors', 'in', 'the', 'first', 'paragraph', 'is', 'an', 'unhelpful', 'approach', 'to', 'this', 'specific', 'subject', 'note', 'that', 'articles', 'about', 'other', 'sitting', 'Justices', 'have', 'been', 'similarly', 'enhanced', 'and', 'also', 'believe', 'those', 'changes', 'are', 'no', 'improvement', 'In', 'support', 'of', 'my', 'view', 'that', 'this', 'edit', 'should', 'be', 'reverted', 'would', 'invite', 'anyone', 'to', 're', 'visit', 'articles', 'written', 'about', 'the', 'following', 'pairs', 'of', 'jurists', 'A1', 'Benjamin', 'Cardozo', 'A2', 'Learned', 'Hand', 'B1', 'John', 'Marshall', 'Harlan', 'B2', 'John', 'Marshall', 'Harlan', 'II', 'The', 'question', 'becomes', 'Would', 'the', 'current', 'version', 'of', 'the', 'Wikipedia', 'article', 'about', 'any', 'one', 'of', 'them', 'or', 'either', 'pair', 'be', 'improved', 'by', 'academic', 'credentials', 'in', 'the', 'introductory', 'paragraph', 'think', 'not', 'Perhaps', 'it', 'helps', 'to', 'repeat', 'wry', 'argument', 'Kathleen', 'Sullivan', 'of', 'Stanford', 'Law', 'makes', 'when', 'she', 'suggests', 'that', 'some', 'on', 'the', 'Harvard', 'Law', 'faculty', 'wonder', 'how', 'Antonin', 'Scalia', 'avoided', 'learning', 'what', 'others', 'have', 'managed', 'to', 'grasp', 'about', 'the', 'processes', 'of', 'judging', 'would', 'hope', 'this', 'anecdote', 'gently', 'illustrates', 'the', 'point', 'Less', 'humorous', 'but', 'an', 'even', 'stronger', 'argument', 'is', 'the', 'one', 'Clarence', 'Thomas', 'makes', 'when', 'he', 'mentions', 'wanting', 'to', 'return', 'his', 'law', 'degree', 'to', 'Yale', 'At', 'minimum', 'questioning', 'this', 'edit', 'It', 'deserves', 'to', 'be', 'reconsidered', 'Radial', 'symmetry', 'Several', 'now', 'extinct', 'lineages', 'included', 'in', 'the', 'Echinodermata', 'were', 'bilateral', 'such', 'as', 'Homostelea', 'or', 'even', 'asymmetrical', 'such', 'as', 'Cothurnocystis', 'Stylophora', 'There', 'no', 'need', 'to', 'apologize', 'Wikipedia', 'article', 'is', 'made', 'for', 'reconciling', 'knowledge', 'about', 'subject', 'from', 'different', 'sources', 'and', 'you', 've', 'done', 'history', 'studies', 'and', 'not', 'archaeology', 'studies', 'guess', 'could', 'scan', 'the', 'page', 'mail', 'it', 'to', 'you', 'and', 'then', 'you', 'could', 'ask', 'someone', 'to', 'translate', 'the', 'page', 'Yes', 'because', 'the', 'mother', 'of', 'the', 'child', 'in', 'the', 'case', 'against', 'Michael', 'Jackson', 'was', 'studied', 'in', 'here', 'motives', 'and', 'reasonings', 'and', 'judged', 'upon', 'her', 'character', 'just', 'as', 'harshly', 'as', 'Wacko', 'Jacko', 'himself', 'Don', 'tell', 'me', 'to', 'ignore', 'it', 'and', 'incriminate', 'myself', 'am', 'going', 'to', 'continue', 'refuting', 'the', 'bullshit', 'that', 'Jayjg', 'keeps', 'throwing', 'at', 'me', 'Jun', 'UTC', 'Ok', 'But', 'it', 'will', 'take', 'bit', 'of', 'work', 'but', 'can', 'quite', 'picture', 'it', 'Do', 'you', 'have', 'an', 'example', 'can', 'base', 'it', 'on', 'the', 'Duck', 'barnstar', 'for', 'you', 'The', 'Real', 'Life', 'Barnstar', 'lets', 'us', 'be', 'the', 'stars', 'How', 'could', 'post', 'before', 'the', 'block', 'expires', 'The', 'funny', 'thing', 'is', 'you', 'think', 'being', 'uncivil', 'Not', 'sure', 'about', 'heading', 'of', 'Fight', 'for', 'Freedom', 'what', 'will', 'it', 'contain', 'Praise', 'looked', 'at', 'this', 'article', 'about', 'months', 'ago', 'much', 'improved', 'was', 'able', 'to', 'post', 'the', 'above', 'list', 'so', 'quickly', 'because', 'already', 'had', 'it', 'in', 'text', 'file', 'in', 'my', 'hard', 'drive', 've', 'been', 'meaning', 'to', 'get', 'around', 'to', 'updating', 'the', 'sound', 'list', 'for', 'some', 'time', 'now', 'As', 'far', 'as', 'generating', 'interest', 've', 'spent', 'four', 'years', 'trying', 'to', 'drum', 'up', 'more', 'interest', 'in', 'freely', 'licensed', 'full', 'length', 'classical', 'music', 'Unfortunately', 'my', 'attempts', 'failed', 'still', 'effectively', 'the', 'only', 'one', 'who', 'does', 'it', 'The', 'classical', 'music', 'wikiproject', 'was', 'not', 'interested', 'Wikipedia_talk', 'WikiProject_Classical_music', 'Archive_5', 'Need_help', 'Wikipedia_talk', 'WikiProject_Music', 'Archive_3', 'I_could_use_some_helpWikipedia_talk', 'WikiProject_Music', 'Archive_2', 'Raulbot', 'C_and_the_music_list', 'So', 'really', 'had', 'given', 'up', 'trying', 'to', 'interest', 'others', 'The', 'sound', 'list', 'was', 'featured', 'on', 'digg', 'while', 'back', 'It', 'got', 'diggs', 'which', 'is', 'IMO', 'very', 'impressive', 'Well', 'not', 'before', 'the', 'process', 'but', 'before', 'how', 'we', 'do', 'things', 'with', 'subpages', 'His', 'RfA', 'is', 'listed', 'on', 'NoSeptember', 'page', 'and', 'you', 'can', 'find', 'it', 'if', 'you', 'look', 'September', 'think', 'have', 'my', 'differences', 'with', 'El_C', 'to', 'be', 'sure', 'but', 'was', 'surprised', 'to', 'see', 'block', 'so', 'left', 'note', 'Not', 'at', 'all', 'you', 'are', 'making', 'straw', 'man', 'argument', 'here', 'never', 'claimed', 'Donohue', 'had', 'that', 'position', 'rather', 'that', 'practitioners', 'and', 'researchers', 'in', 'the', 'field', 'ignored', 'the', 'DSM', 'position', 'which', 'is', 'exactly', 'what', 'the', 'quote', 'says', 'and', 'also', 'something', 'Donohue', 'agrees', 'with', 'Again', 'was', 'combating', 'the', 'notion', 'that', 'it', 'was', 'absurd', 'part', 'to', 'claim', 'that', 'pedophilia', 'is', 'sexual', 'orientation', 'Since', 'many', 'researchers', 'hold', 'this', 'position', 'it', 'would', 'be', 'unfair', 'to', 'call', 'it', 'absurd', 'The', 'disorder', 'part', 'is', 'divided', 'in', 'the', 'field', 'some', 'argue', 'that', 'it', 'is', 'not', 'disorder', 'at', 'all', 'some', 'do', 'At', 'the', 'end', 'of', 'the', 'day', 'it', 'is', 'value', 'judgment', 'as', 'Cantor', 'pointed', 'out', 'earlier', 'in', 'the', 'thread', 'not', 'scientific', 'judgement', 'If', 'we', 'choose', 'to', 'make', 'this', 'value', 'judgment', 'in', 'the', 'article', 'it', 'should', 'be', 'stated', 'clearly', 'and', 'not', 'pretend', 'to', 'have', 'scientific', 'basis', 'Mainland', 'Asia', 'includes', 'the', 'lower', 'basin', 'of', 'China', 'Yangtze', 'River', 'as', 'well', 'as', 'Korea', 'But', 'being', 'specific', 'is', 'fine', 'too', 'just', 'found', 'citation', 'for', 'more', 'comprehensive', 'DNA', 'study', 'by', 'Hammer', 'below', 'rather', 'than', 'our', 'generarizations', 'and', 'speculation', 'so', 'far', 'Citation', 'for', 'Yayoi', 'culture', 'was', 'brought', 'to', 'Japan', 'by', 'migrants', 'from', 'Korea', 'who', 'in', 'turn', 'trace', 'their', 'roots', 'to', 'southeast', 'Asia', 'south', 'China', 'DNA', 'study', 'by', 'Hammer', 'Describes', 'the', 'Yayoi', 'migration', 'from', 'Korea', 'based', 'on', 'the', 'SRY', 'genes', 'and', 'other', 'genes', 'with', 'close', 'lineage', 'haplogroups', 'M122', 'and', 'M95', 'Reiterates', 'that', 'the', 'entire', 'haplogroup', 'has', 'been', 'proposed', 'to', 'have', 'Southeast', 'Asian', 'origin', 'Their', 'definition', 'of', 'Southeast', 'Asia', 'includes', 'southern', 'China', 'Then', 'hypothesizes', 'that', 'the', 'dispersals', 'of', 'Neolithic', 'farmers', 'from', 'Southeast', 'Asia', 'also', 'brought', 'haplogroup', 'lineages', 'to', 'Korea', 'and', 'eventually', 'to', 'Japan', 'In', 'the', 'concluding', 'paragraph', 'it', 'states', 'we', 'propose', 'that', 'the', 'Yayoi', 'chromosomes', 'descend', 'from', 'prehistoric', 'farmers', 'that', 'had', 'their', 'origins', 'in', 'southeastern', 'Asia', 'perhaps', 'going', 'back', 'to', 'the', 'origin', 'of', 'agriculture', 'in', 'this', 'region', 'Hammer', 'DNA', 'study', 'is', 'based', 'on', 'global', 'sample', 'consisted', 'of', 'males', 'from', 'Asian', 'populations', 'including', 'six', 'populations', 'sampled', 'from', 'across', 'the', 'Japanese', 'archipelago', 'pretty', 'much', 'everyone', 'from', 'warren', 'county', 'surrounding', 'regions', 'was', 'born', 'at', 'glens', 'falls', 'hospital', 'myself', 'included', 'however', 'not', 'sure', 'this', 'qualifies', 'anyone', 'as', 'being', 'glens', 'falls', 'native', 'rachel', 'ray', 'is', 'believe', 'actually', 'from', 'the', 'town', 'of', 'lake', 'luzerne', 'The', 'preceding', 'unsigned', 'comment', 'was', 'added', 'by', 'August', 'UTC', 'Hi', 'Explicit', 'can', 'you', 'block', 'Fenian', 'for', 'edit', 'warring', 'on', 'the', 'Giant', 'Causeway', 'wp', 'He', 'has', 'made', 'several', 'edits', 'which', 'can', 'only', 'be', 'described', 'as', 'terrorism', 'Notability', 'of', 'Rurika', 'Kasuga', 'tag', 'has', 'been', 'placed', 'on', 'Rurika', 'Kasuga', 'requesting', 'that', 'it', 'be', 'speedily', 'deleted', 'from', 'Wikipedia', 'This', 'has', 'been', 'done', 'because', 'the', 'article', 'seems', 'to', 'be', 'about', 'person', 'group', 'of', 'people', 'band', 'club', 'company', 'or', 'web', 'content', 'but', 'it', 'does', 'not', 'indicate', 'how', 'or', 'why', 'the', 'subject', 'is', 'notable', 'that', 'is', 'why', 'an', 'article', 'about', 'that', 'subject', 'should', 'be', 'included', 'in', 'Wikipedia', 'Under', 'the', 'criteria', 'for', 'speedy', 'deletion', 'articles', 'that', 'do', 'not', 'assert', 'notability', 'may', 'be', 'deleted', 'at', 'any', 'time', 'Please', 'see', 'the', 'guidelines', 'for', 'what', 'is', 'generally', 'accepted', 'as', 'notable', 'and', 'if', 'you', 'can', 'indicate', 'why', 'the', 'subject', 'of', 'this', 'article', 'is', 'notable', 'you', 'may', 'contest', 'the', 'tagging', 'To', 'do', 'this', 'add', 'on', 'the', 'top', 'of', 'the', 'page', 'below', 'the', 'existing', 'db', 'tag', 'and', 'leave', 'note', 'on', 'the', 'article', 'talk', 'page', 'explaining', 'your', 'position', 'Please', 'do', 'not', 'remove', 'the', 'speedy', 'deletion', 'tag', 'yourself', 'but', 'don', 'hesitate', 'to', 'add', 'information', 'to', 'the', 'article', 'that', 'would', 'confirm', 'its', 'subject', 'notability', 'under', 'the', 'guidelines', 'For', 'guidelines', 'on', 'specific', 'types', 'of', 'articles', 'you', 'may', 'want', 'to', 'check', 'out', 'our', 'criteria', 'for', 'biographies', 'for', 'web', 'sites', 'for', 'bands', 'or', 'for', 'companies', 'Feel', 'free', 'to', 'leave', 'note', 'on', 'my', 'talk', 'page', 'if', 'you', 'have', 'any', 'questions', 'about', 'this', 'Sure', 'but', 'the', 'lead', 'must', 'briefly', 'summarize', 'Armenia', 'history', 'simply', 'added', 'what', 'found', 'necessary', 'If', 'anyone', 'thinks', 'this', 'or', 'that', 'sentence', 'is', 'redundant', 'for', 'the', 'lead', 'they', 'are', 'welcome', 'to', 'remove', 'make', 'edits', 'talk', 'TFD', 'think', 'we', 'just', 'eced', 'think', 'we', 'responded', 'to', 'each', 'other', 'without', 'seeing', 'each', 'others', 'responses', 'added', 'something', 'in', 'response', 'to', 'yours', 'but', 'don', 'know', 'if', 'you', 'saw', 'mine', 'WP', 'CHICAGO', 'WP', 'FOUR', 'You', 'are', 'gay', 'or', 'antisemmitian', 'Archangel', 'WHite', 'Tiger', 'Meow', 'Greetingshhh', 'Uh', 'there', 'are', 'two', 'ways', 'why', 'you', 'do', 'erased', 'my', 'comment', 'about', 'WW2', 'that', 'holocaust', 'was', 'brutally', 'slaying', 'of', 'Jews', 'and', 'not', 'gays', 'Gypsys', 'Slavs', 'anyone', 'If', 'you', 'are', 'anti', 'semitian', 'than', 'shave', 'your', 'head', 'bald', 'and', 'go', 'to', 'the', 'skinhead', 'meetings', 'If', 'you', 'doubt', 'words', 'of', 'the', 'Bible', 'that', 'homosexuality', 'is', 'deadly', 'sin', 'make', 'pentagram', 'tatoo', 'on', 'your', 'forehead', 'go', 'to', 'the', 'satanistic', 'masses', 'with', 'your', 'gay', 'pals', 'First', 'and', 'last', 'warning', 'you', 'fucking', 'gay', 'won', 'appreciate', 'if', 'any', 'more', 'nazi', 'shwain', 'would', 'write', 'in', 'my', 'page', 'don', 'wish', 'to', 'talk', 'to', 'you', 'anymore', 'Beware', 'of', 'the', 'Dark', 'Side', 'FUCK', 'YOUR', 'FILTHY', 'MOTHER', 'IN', 'THE', 'ASS', 'DRY', 'Sorry', 'sorry', 'screwed', 'around', 'with', 'someones', 'talk', 'page', 'It', 'was', 'very', 'bad', 'to', 'do', 'know', 'how', 'having', 'the', 'templates', 'on', 'their', 'talk', 'page', 'helps', 'you', 'assert', 'your', 'dominance', 'over', 'them', 'know', 'should', 'bow', 'down', 'to', 'the', 'almighty', 'administrators', 'But', 'then', 'again', 'going', 'to', 'go', 'play', 'outside', 'with', 'your', 'mom', 'don', 'believe', 'the', 'Lisak', 'criticism', 'present', 'there', 'conforms', 'with', 'the', 'NPV', 'rule', 'Lisak', 'doesn', 'have', 'neutral', 'point', 'of', 'view', 'to', 'begin', 'with', 'If', 'an', 'offer', 'to', 'polygraph', 'or', 'even', 'concerned', 'review', 'of', 'polygraph', 'results', 'shocks', 'complainant', 'into', 'thinking', 'her', 'lies', 'have', 'been', 'uncovered', 'the', 'recantation', 'is', 'still', 'perfectly', 'valid', 'If', 'you', 'know', 'you', 'are', 'telling', 'the', 'truth', 'you', 'will', 'argue', 'with', 'machine', 'or', 'investigator', 'Also', 'part', 'of', 'Kanin', 'research', 'was', 'followup', 'of', 'the', 'recanted', 'story', 'where', 'possible', 'to', 'verify', 'if', 'any', 'were', 'false', 'recantations', 'In', 'all', 'followups', 'the', 'recanted', 'version', 'of', 'events', 'matched', 'what', 'the', 'accused', 'said', 'happened', 'Arguing', 'that', 'Lisak', 'is', 'respected', 'PHD', 'is', 'baseless', 'if', 'Kanin', 'is', 'respected', 'PHD', 'agree', 'that', 'my', 'edit', 'wasn', 'as', 'neutral', 'as', 'possible', 'though', 'so', 'apologize', 'for', 'that', 'Still', 'something', 'must', 'be', 'done', 'here', 'You', 'had', 'point', 'and', 'it', 'now', 'ammended', 'with', 'appropriate', 'encyclopedic', 'notability', 'significance', 'In', 'other', 'words', 'you', 're', 'too', 'lazy', 'to', 'actually', 'point', 'anything', 'out', 'Until', 'you', 'change', 'that', 'approach', 'the', 'tag', 'goes', 'As', 'for', 'your', 'claims', 'of', 'stalking', 'that', 'is', 'absolute', 'rubbish', 'and', 'serves', 'only', 'to', 'aggravate', 'the', 'situation', 'have', 'assumed', 'good', 'faith', 'and', 'good', 'intentions', 'on', 'your', 'part', 'and', 'have', 'never', 'suggested', 'or', 'seen', 'reason', 'to', 'suggest', 'that', 'you', 'might', 'have', 'some', 'ulterior', 'motive', 'in', 'mass', 'adding', 'links', 'to', 'one', 'specific', 'company', 'web', 'page', 'Nor', 'for', 'that', 'matter', 'have', 'ever', 'made', 'any', 'suggestion', 'that', 'this', 'is', 'an', 'administrative', 'matter', 'or', 'even', 'mentioned', 'such', 'role', 'Clearly', 'as', 'party', 'to', 'this', 'disagreement', 'would', 'not', 'do', 'so', 'at', 'any', 'rate', 'as', 'it', 'would', 'be', 'conflict', 'of', 'interest', 'would', 'ask', 'that', 'you', 'thus', 'extend', 'the', 'same', 'good', 'faith', 'toward', 'me', 'rather', 'than', 'making', 'spurious', 'and', 'unfounded', 'accusations', 'chatspy', 'Jmabel', 'in', 'regards', 'to', 'predominant', 'scholary', 'consensus', 'who', 'is', 'it', 'that', 'allegedly', 'claims', 'despite', 'Third', 'Way', 'rhetoric', 'fascism', 'in', 'power', 'functioned', 'rather', 'consistently', 'as', 'right', 'wing', 'force', 'As', 'far', 'as', 'aware', 'owning', 'numerous', 'books', 'on', 'the', 'subject', 'that', 'is', 'not', 'the', 'scholary', 'consensus', 'at', 'all', 'The', 'consensus', 'developed', 'by', 'respected', 'scholars', 'of', 'fascism', 'who', 'write', 'in', 'manner', 'which', 'is', 'not', 'bias', 'to', 'any', 'interest', 'group', 'such', 'as', 'Roger', 'Griffin', 'Hamish', 'McDonald', 'Roger', 'Eatwell', 'and', 'Zeev', 'Sternhell', 'all', 'recongise', 'fascism', 'as', 'Third', 'Way', 'as', 'the', 'references', 'show', 'The', 'only', 'dissenters', 'aware', 'of', 'who', 'seem', 'to', 'think', 'fascism', 'has', 'absoutely', 'no', 'leftist', 'connections', 'and', 'is', 'merely', 'radical', 'right', 'system', 'are', 'street', 'level', 'socialists', 'who', 'want', 'to', 'put', 'as', 'much', 'distance', 'between', 'the', 'movements', 'as', 'possible', 'This', 'of', 'course', 'does', 'not', 'come', 'from', 'educated', 'people', 'in', 'position', 'to', 'write', 'books', 'For', 'example', 'even', 'the', 'foremost', 'scholary', 'expert', 'on', 'Fascism', 'and', 'former', 'member', 'of', 'both', 'the', 'Communist', 'Party', 'and', 'then', 'Socialist', 'Party', 'of', 'Italy', 'Renzo', 'De', 'Felice', 'doesn', 'try', 'to', 'cover', 'up', 'its', 'socialistic', 'origins', 'and', 'third', 'way', 'status', 'This', 'is', 'man', 'who', 'has', 'wrote', 'definitive', 'seven', 'volume', 'piece', 'on', 'Mussolini']\n"
     ]
    }
   ],
   "source": [
    "# Call the List flatter\n",
    "flat_tokens = flatten(token_per_row)\n",
    "\n",
    "print(flat_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the stopwords\n",
    "# Already installed so will comment it out\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Need to remove stop words too\n",
    "# changing the stopwords from a list to a set (Performance Upgrade)\n",
    "ENGLISH_STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword Removal\n",
    "Prior to removing stopwords, one has to change the case of the tokens (words) to be lowercase, which is also what is asked of us to do within the ToDo list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3291\n"
     ]
    }
   ],
   "source": [
    "# Changing all words into lowercase\n",
    "# Using a list comprehension to change it more efficienty\n",
    "# (They're better than for loops)\n",
    "flat_tokens = [token.lower() for token in flat_tokens]\n",
    "\n",
    "# Was 'Explanation', should be 'explanation'\n",
    "print(len(flat_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1762\n"
     ]
    }
   ],
   "source": [
    "# Actually removing stopwords\n",
    "stop_free = [token for token in flat_tokens if token not in ENGLISH_STOPWORDS]\n",
    "\n",
    "print(len(stop_free))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Changing the word back to its roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using porterstemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed_words = [stemmer.stem(word) for word in stop_free]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explan', 'edit', 'made', 'usernam', 'hardcor', 'metallica', 'fan', 'revert', 'vandal', 'closur', 'ga', 'vote', 'new', 'york', 'doll', 'fac', 'pleas', 'remov', 'templat', 'talk', 'page', 'sinc', 'retir', 'aww', 'match', 'background', 'colour', 'seemingli', 'stuck', 'thank', 'talk', 'januari', 'utc', 'hey', 'man', 'realli', 'tri', 'edit', 'war', 'guy', 'constantli', 'remov', 'relev', 'inform', 'talk', 'edit', 'instead', 'talk', 'page', 'seem', 'care', 'format', 'actual', 'info', 'make', 'real', 'suggest', 'improv', 'wonder', 'section', 'statist', 'later', 'subsect', 'type', 'accid', 'think', 'refer', 'may', 'need', 'tidi', 'exact', 'format', 'ie', 'date', 'format', 'etc', 'later', 'one', 'els', 'first', 'prefer', 'format', 'style', 'refer', 'want', 'pleas', 'let', 'know', 'appear', 'backlog', 'articl', 'review', 'guess', 'may', 'delay', 'review', 'turn', 'list', 'relev', 'form', 'eg', 'wikipedia', 'good_article_nomin', 'transport', 'sir', 'hero', 'chanc', 'rememb', 'page', 'congratul', 'well', 'use', 'tool', 'well', 'talk', 'cocksuck', 'piss', 'around', 'work', 'vandal', 'matt', 'shirvington', 'articl', 'revert', 'pleas', 'ban', 'sorri', 'word', 'nonsens', 'offens', 'anyway', 'intend', 'write', 'anyth', 'articl', 'wow', 'would', 'jump', 'vandal', 'mere', 'request', 'encycloped', 'one', 'use', 'school', 'refer', 'select', 'breed', 'page', 'almost', 'stub', 'point', 'anim', 'breed', 'short', 'messi', 'articl', 'give', 'info', 'must', 'someon', 'around', 'expertis', 'eugen', 'align', 'subject', 'contrari', 'dulithgow', 'fair', 'use', 'rational', 'imag', 'wonju', 'jpg', 'thank', 'upload', 'imag', 'wonju', 'jpg', 'notic', 'imag', 'page', 'specifi', 'imag', 'use', 'fair', 'use', 'explan', 'rational', 'use', 'wikipedia', 'articl', 'constitut', 'fair', 'use', 'addit', 'boilerpl', 'fair', 'use', 'templat', 'must', 'also', 'write', 'imag', 'descript', 'page', 'specif', 'explan', 'rational', 'use', 'imag', 'articl', 'consist', 'fair', 'use', 'pleas', 'go', 'imag', 'descript', 'page', 'edit', 'includ', 'fair', 'use', 'rational', 'upload', 'fair', 'use', 'media', 'consid', 'check', 'specifi', 'fair', 'use', 'rational', 'page', 'find', 'list', 'imag', 'page', 'edit', 'click', 'contribut', 'link', 'locat', 'top', 'wikipedia', 'page', 'log', 'select', 'imag', 'dropdown', 'box', 'note', 'fair', 'use', 'imag', 'upload', 'may', 'lack', 'explan', 'delet', 'one', 'week', 'upload', 'describ', 'criteria', 'speedi', 'delet', 'question', 'pleas', 'ask', 'media', 'copyright', 'question', 'page', 'thank', 'talk', 'contrib', 'unspecifi', 'sourc', 'imag', 'wonju', 'jpg', 'thank', 'upload', 'imag', 'wonju', 'jpg', 'notic', 'file', 'descript', 'page', 'current', 'specifi', 'creat', 'content', 'copyright', 'statu', 'unclear', 'creat', 'file', 'need', 'specifi', 'owner', 'copyright', 'obtain', 'websit', 'link', 'websit', 'taken', 'togeth', 'restat', 'websit', 'term', 'use', 'content', 'usual', 'suffici', 'inform', 'howev', 'copyright', 'holder', 'differ', 'websit', 'publish', 'copyright', 'also', 'acknowledg', 'well', 'ad', 'sourc', 'pleas', 'add', 'proper', 'copyright', 'licens', 'tag', 'file', 'one', 'alreadi', 'creat', 'took', 'pictur', 'audio', 'video', 'tag', 'use', 'releas', 'gfdl', 'believ', 'media', 'meet', 'criteria', 'wikipedia', 'fair', 'use', 'use', 'tag', 'one', 'tag', 'list', 'wikipedia', 'imag', 'copyright', 'tag', 'fair', 'use', 'see', 'wikipedia', 'imag', 'copyright', 'tag', 'full', 'list', 'copyright', 'tag', 'use', 'upload', 'file', 'consid', 'check', 'specifi', 'sourc', 'tag', 'find', 'list', 'file', 'upload', 'follow', 'link', 'unsourc', 'untag', 'imag', 'may', 'delet', 'one', 'week', 'tag', 'describ', 'criteria', 'speedi', 'delet', 'imag', 'copyright', 'non', 'free', 'licens', 'per', 'wikipedia', 'fair', 'use', 'imag', 'delet', 'hour', 'question', 'pleas', 'ask', 'media', 'copyright', 'question', 'page', 'thank', 'talk', 'contrib', 'bbq', 'man', 'let', 'discuss', 'mayb', 'phone', 'hey', 'talk', 'exclus', 'group', 'wp', 'taliban', 'good', 'destroy', 'self', 'appoint', 'purist', 'gang', 'one', 'ask', 'question', 'abt', 'anti', 'social', 'destruct', 'non', 'contribut', 'wp', 'ask', 'sityush', 'clean', 'behavior', 'issu', 'nonsens', 'warn', 'start', 'throw', 'accus', 'warn', 'let', 'review', 'edit', 'make', 'ad', 'hominem', 'attack', 'go', 'strengthen', 'argument', 'mere', 'make', 'look', 'like', 'abus', 'power', 'admin', 'edit', 'relev', 'probabl', 'singl', 'talk', 'event', 'int', 'news', 'late', 'absenc', 'notabl', 'sinc', 'live', 'ex', 'presid', 'attend', 'certainli', 'notabl', 'dedic', 'aircracft', 'carrier', 'intend', 'revert', 'edit', 'hope', 'attract', 'attent', 'admin', 'will', 'look', 'issu', 'throw', 'accus', 'around', 'quit', 'liber', 'perhap', 'achiev', 'level', 'civil', 'ration', 'discuss', 'topic', 'resolv', 'matter', 'peac', 'oh', 'girl', 'start', 'argument', 'stuck', 'nose', 'belong', 'believ', 'argument', 'yvesnimmo', 'like', 'said', 'situat', 'settl', 'apolog', 'thank', 'juelz', 'santana', 'age', 'juelz', 'santana', 'year', 'old', 'came', 'februari', 'th', 'make', 'juelz', 'turn', 'make', 'song', 'diplomat', 'third', 'neff', 'sign', 'cam', 'label', 'roc', 'fella', 'year', 'old', 'come', 'singl', 'santana', 'town', 'ye', 'born', 'realli', 'could', 'older', 'lloyd', 'bank', 'could', 'birthday', 'pass', 'homi', 'neff', 'year', 'old', 'juelz', 'death', 'god', 'forbid', 'think', 'equal', 'go', 'cacul', 'stop', 'chang', 'year', 'birth', 'god', 'bye', 'look', 'come', 'think', 'com', 'back', 'tosser', 'redirect', 'talk', 'voydan', 'pop', 'georgiev', 'chernodrinski', 'mitsurugi', 'point', 'made', 'sens', 'argu', 'includ', 'hindi', 'ryo', 'sakazaki', 'page', 'includ', 'inform', 'mean', 'bother', 'see', 'write', 'someth', 'regard', 'remov', 'anyth', 'post', 'oh', 'well', 'acctual', 'discuss', 'even', 'better', 'like', 'ask', 'take', 'closer', 'look', 'prematur', 'wrestl', 'death', 'catagori', 'men', 'list', 'sure', 'men', 'belong', 'togeth', 'catagori', 'anyth', 'think', 'catagori', 'besid', 'delt', 'regard', 'recent', 'edit', 'pleas', 'read', 'wp', 'filmplot', 'edit', 'film', 'articl', 'edit', 'simpli', 'good', 'entir', 'mani', 'unnecessari', 'detail', 'bad', 'write', 'pleas', 'stop', 'damag', 'good', 'know', 'yeah', 'studi', 'deepu', 'snowflak', 'alway', 'symmetr', 'geometri', 'state', 'snowflak', 'alway', 'six', 'symmetr', 'arm', 'assert', 'simpli', 'true', 'accord', 'kenneth', 'libbrecht', 'rather', 'unattract', 'irregular', 'crystal', 'far', 'common', 'varieti', 'someon', 'realli', 'need', 'take', 'look', 'site', 'get', 'fact', 'still', 'see', 'decent', 'number', 'falsiti', 'page', 'forgiv', 'im', 'new', 'dont', 'want', 'edit', 'anyth', 'signpost', 'septemb', 'read', 'signpost', 'full', 'singl', 'page', 'unsubscrib', 'consid', 'st', 'paragraph', 'edit', 'understand', 'reason', 'recent', 'edit', 'articl', 'sure', 'data', 'necessarili', 'wrong', 'rather', 'persuad', 'strategi', 'introduc', 'academ', 'honor', 'first', 'paragraph', 'unhelp', 'approach', 'specif', 'subject', 'note', 'articl', 'sit', 'justic', 'similarli', 'enhanc', 'also', 'believ', 'chang', 'improv', 'support', 'view', 'edit', 'revert', 'would', 'invit', 'anyon', 'visit', 'articl', 'written', 'follow', 'pair', 'jurist', 'a1', 'benjamin', 'cardozo', 'a2', 'learn', 'hand', 'b1', 'john', 'marshal', 'harlan', 'b2', 'john', 'marshal', 'harlan', 'ii', 'question', 'becom', 'would', 'current', 'version', 'wikipedia', 'articl', 'one', 'either', 'pair', 'improv', 'academ', 'credenti', 'introductori', 'paragraph', 'think', 'perhap', 'help', 'repeat', 'wri', 'argument', 'kathleen', 'sullivan', 'stanford', 'law', 'make', 'suggest', 'harvard', 'law', 'faculti', 'wonder', 'antonin', 'scalia', 'avoid', 'learn', 'other', 'manag', 'grasp', 'process', 'judg', 'would', 'hope', 'anecdot', 'gentli', 'illustr', 'point', 'less', 'humor', 'even', 'stronger', 'argument', 'one', 'clarenc', 'thoma', 'make', 'mention', 'want', 'return', 'law', 'degre', 'yale', 'minimum', 'question', 'edit', 'deserv', 'reconsid', 'radial', 'symmetri', 'sever', 'extinct', 'lineag', 'includ', 'echinodermata', 'bilater', 'homostelea', 'even', 'asymmetr', 'cothurnocysti', 'stylophora', 'need', 'apolog', 'wikipedia', 'articl', 'made', 'reconcil', 'knowledg', 'subject', 'differ', 'sourc', 'done', 'histori', 'studi', 'archaeolog', 'studi', 'guess', 'could', 'scan', 'page', 'mail', 'could', 'ask', 'someon', 'translat', 'page', 'ye', 'mother', 'child', 'case', 'michael', 'jackson', 'studi', 'motiv', 'reason', 'judg', 'upon', 'charact', 'harshli', 'wacko', 'jacko', 'tell', 'ignor', 'incrimin', 'go', 'continu', 'refut', 'bullshit', 'jayjg', 'keep', 'throw', 'jun', 'utc', 'ok', 'take', 'bit', 'work', 'quit', 'pictur', 'exampl', 'base', 'duck', 'barnstar', 'real', 'life', 'barnstar', 'let', 'us', 'star', 'could', 'post', 'block', 'expir', 'funni', 'thing', 'think', 'uncivil', 'sure', 'head', 'fight', 'freedom', 'contain', 'prais', 'look', 'articl', 'month', 'ago', 'much', 'improv', 'abl', 'post', 'list', 'quickli', 'alreadi', 'text', 'file', 'hard', 'drive', 'mean', 'get', 'around', 'updat', 'sound', 'list', 'time', 'far', 'gener', 'interest', 'spent', 'four', 'year', 'tri', 'drum', 'interest', 'freeli', 'licens', 'full', 'length', 'classic', 'music', 'unfortun', 'attempt', 'fail', 'still', 'effect', 'one', 'classic', 'music', 'wikiproject', 'interest', 'wikipedia_talk', 'wikiproject_classical_mus', 'archive_5', 'need_help', 'wikipedia_talk', 'wikiproject_mus', 'archive_3', 'i_could_use_some_helpwikipedia_talk', 'wikiproject_mus', 'archive_2', 'raulbot', 'c_and_the_music_list', 'realli', 'given', 'tri', 'interest', 'other', 'sound', 'list', 'featur', 'digg', 'back', 'got', 'digg', 'imo', 'impress', 'well', 'process', 'thing', 'subpag', 'rfa', 'list', 'noseptemb', 'page', 'find', 'look', 'septemb', 'think', 'differ', 'el_c', 'sure', 'surpris', 'see', 'block', 'left', 'note', 'make', 'straw', 'man', 'argument', 'never', 'claim', 'donohu', 'posit', 'rather', 'practition', 'research', 'field', 'ignor', 'dsm', 'posit', 'exactli', 'quot', 'say', 'also', 'someth', 'donohu', 'agre', 'combat', 'notion', 'absurd', 'part', 'claim', 'pedophilia', 'sexual', 'orient', 'sinc', 'mani', 'research', 'hold', 'posit', 'would', 'unfair', 'call', 'absurd', 'disord', 'part', 'divid', 'field', 'argu', 'disord', 'end', 'day', 'valu', 'judgment', 'cantor', 'point', 'earlier', 'thread', 'scientif', 'judgement', 'choos', 'make', 'valu', 'judgment', 'articl', 'state', 'clearli', 'pretend', 'scientif', 'basi', 'mainland', 'asia', 'includ', 'lower', 'basin', 'china', 'yangtz', 'river', 'well', 'korea', 'specif', 'fine', 'found', 'citat', 'comprehens', 'dna', 'studi', 'hammer', 'rather', 'generar', 'specul', 'far', 'citat', 'yayoi', 'cultur', 'brought', 'japan', 'migrant', 'korea', 'turn', 'trace', 'root', 'southeast', 'asia', 'south', 'china', 'dna', 'studi', 'hammer', 'describ', 'yayoi', 'migrat', 'korea', 'base', 'sri', 'gene', 'gene', 'close', 'lineag', 'haplogroup', 'm122', 'm95', 'reiter', 'entir', 'haplogroup', 'propos', 'southeast', 'asian', 'origin', 'definit', 'southeast', 'asia', 'includ', 'southern', 'china', 'hypothes', 'dispers', 'neolith', 'farmer', 'southeast', 'asia', 'also', 'brought', 'haplogroup', 'lineag', 'korea', 'eventu', 'japan', 'conclud', 'paragraph', 'state', 'propos', 'yayoi', 'chromosom', 'descend', 'prehistor', 'farmer', 'origin', 'southeastern', 'asia', 'perhap', 'go', 'back', 'origin', 'agricultur', 'region', 'hammer', 'dna', 'studi', 'base', 'global', 'sampl', 'consist', 'male', 'asian', 'popul', 'includ', 'six', 'popul', 'sampl', 'across', 'japanes', 'archipelago', 'pretti', 'much', 'everyon', 'warren', 'counti', 'surround', 'region', 'born', 'glen', 'fall', 'hospit', 'includ', 'howev', 'sure', 'qualifi', 'anyon', 'glen', 'fall', 'nativ', 'rachel', 'ray', 'believ', 'actual', 'town', 'lake', 'luzern', 'preced', 'unsign', 'comment', 'ad', 'august', 'utc', 'hi', 'explicit', 'block', 'fenian', 'edit', 'war', 'giant', 'causeway', 'wp', 'made', 'sever', 'edit', 'describ', 'terror', 'notabl', 'rurika', 'kasuga', 'tag', 'place', 'rurika', 'kasuga', 'request', 'speedili', 'delet', 'wikipedia', 'done', 'articl', 'seem', 'person', 'group', 'peopl', 'band', 'club', 'compani', 'web', 'content', 'indic', 'subject', 'notabl', 'articl', 'subject', 'includ', 'wikipedia', 'criteria', 'speedi', 'delet', 'articl', 'assert', 'notabl', 'may', 'delet', 'time', 'pleas', 'see', 'guidelin', 'gener', 'accept', 'notabl', 'indic', 'subject', 'articl', 'notabl', 'may', 'contest', 'tag', 'add', 'top', 'page', 'exist', 'db', 'tag', 'leav', 'note', 'articl', 'talk', 'page', 'explain', 'posit', 'pleas', 'remov', 'speedi', 'delet', 'tag', 'hesit', 'add', 'inform', 'articl', 'would', 'confirm', 'subject', 'notabl', 'guidelin', 'guidelin', 'specif', 'type', 'articl', 'may', 'want', 'check', 'criteria', 'biographi', 'web', 'site', 'band', 'compani', 'feel', 'free', 'leav', 'note', 'talk', 'page', 'question', 'sure', 'lead', 'must', 'briefli', 'summar', 'armenia', 'histori', 'simpli', 'ad', 'found', 'necessari', 'anyon', 'think', 'sentenc', 'redund', 'lead', 'welcom', 'remov', 'make', 'edit', 'talk', 'tfd', 'think', 'ece', 'think', 'respond', 'without', 'see', 'other', 'respons', 'ad', 'someth', 'respons', 'know', 'saw', 'mine', 'wp', 'chicago', 'wp', 'four', 'gay', 'antisemmitian', 'archangel', 'white', 'tiger', 'meow', 'greetingshhh', 'uh', 'two', 'way', 'eras', 'comment', 'ww2', 'holocaust', 'brutal', 'slay', 'jew', 'gay', 'gypsi', 'slav', 'anyon', 'anti', 'semitian', 'shave', 'head', 'bald', 'go', 'skinhead', 'meet', 'doubt', 'word', 'bibl', 'homosexu', 'deadli', 'sin', 'make', 'pentagram', 'tatoo', 'forehead', 'go', 'satanist', 'mass', 'gay', 'pal', 'first', 'last', 'warn', 'fuck', 'gay', 'appreci', 'nazi', 'shwain', 'would', 'write', 'page', 'wish', 'talk', 'anymor', 'bewar', 'dark', 'side', 'fuck', 'filthi', 'mother', 'ass', 'dri', 'sorri', 'sorri', 'screw', 'around', 'someon', 'talk', 'page', 'bad', 'know', 'templat', 'talk', 'page', 'help', 'assert', 'domin', 'know', 'bow', 'almighti', 'administr', 'go', 'go', 'play', 'outsid', 'mom', 'believ', 'lisak', 'critic', 'present', 'conform', 'npv', 'rule', 'lisak', 'neutral', 'point', 'view', 'begin', 'offer', 'polygraph', 'even', 'concern', 'review', 'polygraph', 'result', 'shock', 'complain', 'think', 'lie', 'uncov', 'recant', 'still', 'perfectli', 'valid', 'know', 'tell', 'truth', 'argu', 'machin', 'investig', 'also', 'part', 'kanin', 'research', 'followup', 'recant', 'stori', 'possibl', 'verifi', 'fals', 'recant', 'followup', 'recant', 'version', 'event', 'match', 'accus', 'said', 'happen', 'argu', 'lisak', 'respect', 'phd', 'baseless', 'kanin', 'respect', 'phd', 'agre', 'edit', 'neutral', 'possibl', 'though', 'apolog', 'still', 'someth', 'must', 'done', 'point', 'ammend', 'appropri', 'encycloped', 'notabl', 'signific', 'word', 'lazi', 'actual', 'point', 'anyth', 'chang', 'approach', 'tag', 'goe', 'claim', 'stalk', 'absolut', 'rubbish', 'serv', 'aggrav', 'situat', 'assum', 'good', 'faith', 'good', 'intent', 'part', 'never', 'suggest', 'seen', 'reason', 'suggest', 'might', 'ulterior', 'motiv', 'mass', 'ad', 'link', 'one', 'specif', 'compani', 'web', 'page', 'matter', 'ever', 'made', 'suggest', 'administr', 'matter', 'even', 'mention', 'role', 'clearli', 'parti', 'disagr', 'would', 'rate', 'would', 'conflict', 'interest', 'would', 'ask', 'thu', 'extend', 'good', 'faith', 'toward', 'rather', 'make', 'spuriou', 'unfound', 'accus', 'chatspi', 'jmabel', 'regard', 'predomin', 'scholari', 'consensu', 'allegedli', 'claim', 'despit', 'third', 'way', 'rhetor', 'fascism', 'power', 'function', 'rather', 'consist', 'right', 'wing', 'forc', 'far', 'awar', 'own', 'numer', 'book', 'subject', 'scholari', 'consensu', 'consensu', 'develop', 'respect', 'scholar', 'fascism', 'write', 'manner', 'bia', 'interest', 'group', 'roger', 'griffin', 'hamish', 'mcdonald', 'roger', 'eatwel', 'zeev', 'sternhel', 'recongis', 'fascism', 'third', 'way', 'refer', 'show', 'dissent', 'awar', 'seem', 'think', 'fascism', 'absout', 'leftist', 'connect', 'mere', 'radic', 'right', 'system', 'street', 'level', 'socialist', 'want', 'put', 'much', 'distanc', 'movement', 'possibl', 'cours', 'come', 'educ', 'peopl', 'posit', 'write', 'book', 'exampl', 'even', 'foremost', 'scholari', 'expert', 'fascism', 'former', 'member', 'communist', 'parti', 'socialist', 'parti', 'itali', 'renzo', 'de', 'felic', 'tri', 'cover', 'socialist', 'origin', 'third', 'way', 'statu', 'man', 'wrote', 'definit', 'seven', 'volum', 'piec', 'mussolini']\n"
     ]
    }
   ],
   "source": [
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a lot of words are either missing an e at the end, or not even english anymore, that is due to Stemmer using a crude old method, which is aimed for speed and efficiency, unlike lemmatizaton which morphologically analyses lexical changes in words to revert them back to their roots, unlike the chopping of \"commonly found prefixes/suffixes\" which stemming does."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
