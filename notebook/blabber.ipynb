{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blabber Cleaning\n",
    "#### (By: Mark Ehab Aziz)\n",
    "#### (Built Under: Python 3.11.4)\n",
    "Filtering out and cleaning text data.\n",
    "As tasked inside the 'to do.txt'.\n",
    "\n",
    "Ensure the presence of nltk package using `pip install nltk`.\n",
    "\n",
    "Following usage of nltk should not require further dependencies than the basic install and stopwords.\n",
    "\n",
    "If anything; Ensure presence of `nltk`, the download for stopwords is within the cells and will download automatically should it not detect any instance of predownloaded stopwords for itself.\n",
    "\n",
    "## Note:\n",
    "You may encounter (Window Not Responding), in which case; kindly wait for it, as the notebook's size seems to increase by a lot after running the stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd                         # Loading Data\n",
    "import numpy as np\n",
    "import nltk                                 # Required to download stopwords set\n",
    "from nltk.corpus import stopwords           # Load Stopwords\n",
    "from nltk.tokenize import regexp_tokenize   # To Tokenize words with Regex Expressions\n",
    "from nltk.tokenize import word_tokenize     # Tokenizer too\n",
    "from nltk.stem import PorterStemmer         # Stemming words\n",
    "from nltk.stem import SnowballStemmer       # Improved Stemming\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into environment\n",
    "# Using two methods (As stated in my previous projects)\n",
    "# 1. Path working within my git repo\n",
    "blab = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# 2. Path when data is within the same folder\n",
    "#blab = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Using `.head(n)` to show the first $n^{th}$ rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining n rows to see\n",
    "n = 5\n",
    "\n",
    "# Showing head\n",
    "blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated by our todo list, we are only tasked with cleaning of the text, so we'll be focusing on `comment_text`.\n",
    "\n",
    "Referring to our todo list once again, we will be dropping `id`, `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`; as we are not concerned with classifying the sentiment or the meaning behind any of the comments.\n",
    "\n",
    "Reminder for what to be done:\n",
    "- Read Text\n",
    "- Clean Text (Capitalisation, punctuation)\n",
    "- Remove Stop Words\n",
    "- Tokenization\n",
    "- Stemming\n",
    "\n",
    "Under no aforementioned task will we be using the columns I have mentioned to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\r\\nWhy the edits made under my use...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining list of columns to be dropped\n",
    "col_droppable = [\"id\"]\n",
    "\n",
    "# Dropping\n",
    "txt_blab = blab.drop(columns = col_droppable)\n",
    "\n",
    "# Viewing\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation  Why the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"  More  I can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing '\\n' '\\r' '\\t' from every line\n",
    "txt_blab.replace(r'[\\r\\n\\t]', ' ', regex = True, inplace=True)\n",
    "\n",
    "# As noted, there are no escape characters for spaces, as new line or tab\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Above Sentences\n",
    "Using the NLTK library for Python; will be copy-pasting or creating patterns that are enough to extract words, starting with either upper or lower case letters.\n",
    "\n",
    "This may violate the order of operations specified in the ToDo list, as cleaning data preceeds tokenization, but `regexp_tokenize()` takes care of both steps anyway, through just matching what is specified within the regex, as only 'Latin Alphabet' ranges are specified (`A-Za-z`), it will automatically unmatch any special character or non-alphabet character, ignores punctuation as well.\n",
    "\n",
    "Will also be removing the URLs as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regex patterns\n",
    "# Match words starting with Uppercase letters\n",
    "upper_words = r\"([A-Z])\\w+\"\n",
    "\n",
    "# Match Words that start with either Upper/lowercase letters\n",
    "upper_lower_words = r\"[A-Za-z]\\w+\"\n",
    "\n",
    "# Match URLs\n",
    "url_pattern = r\"(http|ftp|https):\\/\\/([\\w+?\\.\\w+])+([a-zA-Z0-9\\~\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)_\\-\\=\\+\\\\\\/\\?\\.\\:\\;\\'\\,]*)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation  Why the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"  More  I can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing URLs (Standard URL Scheme, There still exist instances\n",
    "# of just 'https' or 'http' randomly written, they will just be\n",
    "# treated like normal words and tokenized as the rest)\n",
    "txt_blab.replace(url_pattern, '', regex = True, inplace = True)\n",
    "\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Iterating over each row of the given textual data, accessing as a string instead of a usual row in order to yield the full entry.\n",
    "\n",
    "Using regex to tokenize words by matching pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a list of tokens, to hold tokens of each entry\n",
    "# Probably better to use a dictionary if we care about count (?)\n",
    "# Still have to access every token and change to lower (Taken care of in flat list)\n",
    "token_per_row = []\n",
    "\n",
    "# Start and finish indecies of iterator\n",
    "# Bound to become the length of the file eventually\n",
    "for i in range(txt_blab.shape[0]):\n",
    "    # Grab string fully from dataframe\n",
    "    line = txt_blab.iloc[i,0]\n",
    "\n",
    "    # Append list of tokens\n",
    "    # 2D list of lists; each containing tokens of each row\n",
    "    token_per_row.append(regexp_tokenize(line, upper_lower_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 2D List of Lists\n",
    "# n^2 operation but still gets the job done\n",
    "# Would be better to flatten as soon as\n",
    "# the tokens are fresh out the tokenizer\n",
    "def flatten(list_o_lists):\n",
    "    # init flat list\n",
    "    flat = []\n",
    "\n",
    "    # Loop over every list within the list\n",
    "    for sublist in list_o_lists:\n",
    "        # Loop over every token within the sublist\n",
    "        # being iterated on\n",
    "        for token in sublist:\n",
    "            # Append token to flat list\n",
    "            flat.append(token)\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 'vandalisms', 'just', 'closure', 'on', 'some']\n"
     ]
    }
   ],
   "source": [
    "# Call the List flatter\n",
    "flat_tokens = flatten(token_per_row)\n",
    "\n",
    "print(flat_tokens[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the stopwords\n",
    "# Already installed so will comment it out\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Need to remove stop words too\n",
    "# changing the stopwords from a list to a set (Performance Upgrade)\n",
    "ENGLISH_STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword Removal\n",
    "Prior to removing stopwords, one has to change the case of the tokens (words) to be lowercase, which is also what is asked of us to do within the ToDo list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation\n"
     ]
    }
   ],
   "source": [
    "# Changing all words into lowercase\n",
    "# Using a list comprehension to change it more efficienty\n",
    "# (They're better than for loops)\n",
    "flat_tokens = [token.lower() for token in flat_tokens]\n",
    "\n",
    "# Was 'Explanation', should be 'explanation'\n",
    "print(flat_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5425847\n",
      "10130248\n"
     ]
    }
   ],
   "source": [
    "# Actually removing stopwords\n",
    "stop_free = [token for token in flat_tokens if token not in ENGLISH_STOPWORDS]\n",
    "\n",
    "# Getting how many words remained after removal of stopwords\n",
    "print(len(stop_free))\n",
    "\n",
    "# Getting how many words were tokenized (Both stop and non-stop)\n",
    "print(len(flat_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "Changing the word back to its roots. Through using the 'Porter Algorithm'. (Fast and Effective, Not very accurate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list 1: 1000000\n",
      "Length of list 2: 1000000\n",
      "Length of list 3: 1000000\n",
      "Length of list 4: 500000\n",
      "Length of list 5: 1000000\n",
      "Length of list 6: 425847\n"
     ]
    }
   ],
   "source": [
    "# Using porterstemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Inserting the semmed words into a list\n",
    "# Will be dividing into \"batches\" due to\n",
    "# reaching maximum recursion depth if\n",
    "# if all entries are sent at once\n",
    "stemmed_words0 = [stemmer.stem(word) for word in stop_free[:1000000]]\n",
    "print('Length of list 1: {}'.format(len(stemmed_words0)))\n",
    "stemmed_words1 = [stemmer.stem(word) for word in stop_free[1000000:2000000]]\n",
    "print('Length of list 2: {}'.format(len(stemmed_words1)))\n",
    "stemmed_words2 = [stemmer.stem(word) for word in stop_free[2000000:3000000]]\n",
    "print('Length of list 3: {}'.format(len(stemmed_words2)))\n",
    "\n",
    "# Explaining the 500k word skip:\n",
    "# Kernel would throw an error due to \"Reaching Maximum Recursion Depth\"\n",
    "# on coming across a certain word which seems to have it lock up\n",
    "# after changing the indecies a little, this configuration works best\n",
    "# could probably be fine tuned to find the word that messes it up\n",
    "stemmed_words3 = [stemmer.stem(word) for word in stop_free[3000000:3500000]]\n",
    "print('Length of list 4: {}'.format(len(stemmed_words3)))\n",
    "\n",
    "stemmed_words4 = [stemmer.stem(word) for word in stop_free[4000000:5000000]]\n",
    "print('Length of list 5: {}'.format(len(stemmed_words4)))\n",
    "stemmed_words5 = [stemmer.stem(word) for word in stop_free[5000000:]]\n",
    "print('Length of list 6: {}'.format(len(stemmed_words5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stemmed words: 4925847\n",
      "['explan', 'edit', 'made', 'usernam', 'hardcor', 'metallica', 'fan', 'revert', 'vandal', 'closur']\n"
     ]
    }
   ],
   "source": [
    "# Joining lists\n",
    "total_stemmed_words = stemmed_words0 + stemmed_words1 + stemmed_words2 + stemmed_words3 + stemmed_words4 + stemmed_words5\n",
    "\n",
    "# Printing number of words\n",
    "print('Total number of stemmed words: {}'.format(len(total_stemmed_words)))\n",
    "\n",
    "# Displaying some words\n",
    "print(total_stemmed_words[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a lot of words are either missing an e at the end, or not even english anymore, that is due to Stemmer using a crude old method, which is aimed for speed and efficiency, unlike lemmatizaton which morphologically analyses lexical changes in words to revert them back to their roots, unlike the chopping of \"commonly found prefixes/suffixes\" which stemming does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a bit more searching and digging around, within the NLTK package there exists another variant of the PorterStemmer called SnowballStemmer, which fixes the above issues regarding missing an e or plain out non-english words.\n",
    "\n",
    "It will be used over the porterstemmer for the following tasks, whilst keeping the porter stemmer cells to highlight the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Continuation\n",
    "Relevant tasks were assigned to be done on the same notebook, the are present within the `README.md`, but as a quick reminder I will list them here.\n",
    "\n",
    "1. Bag of Words\n",
    "2. Word Embeddings\n",
    "3. Use BERT and Evaluate\n",
    "\n",
    "# Variable Definition\n",
    "We will be using the following variables carried over from the previous part of this notebook, namely:\n",
    "- `ENGLISH_STOPWORDS`: Constant for holding the stopwords found in the English language.\n",
    "- `flat_tokens`: Tokens from every row parsed into a single list of tokens.\n",
    "- `stop_free`: List of tokens free of stopwords.\n",
    "- `total_stemmed_words`: List of stemmed words from tokens.\n",
    "- `txt_blab`: Dataframe with cleaned comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a stemmer object\n",
    "snowball = SnowballStemmer(\"english\")\n",
    "\n",
    "# Iterate over the flattened list of words\n",
    "total_stemmed_words = [snowball.stem(word) for word in stop_free]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5425847\n",
      "['explan', 'edit', 'made', 'usernam', 'hardcor', 'metallica', 'fan', 'revert', 'vandal', 'closur']\n"
     ]
    }
   ],
   "source": [
    "# Printing number of words\n",
    "print(len(total_stemmed_words))\n",
    "\n",
    "# Print some words\n",
    "print(total_stemmed_words[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually implementing a bag of words\n",
    "# Essentially just a dictionary with word count\n",
    "bag_o_words = {}\n",
    "\n",
    "for token in total_stemmed_words:\n",
    "    if token in bag_o_words:\n",
    "        bag_o_words[token] += 1\n",
    "    else:\n",
    "        bag_o_words[token] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>articl</th>\n",
       "      <td>74137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>page</th>\n",
       "      <td>57083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia</th>\n",
       "      <td>46144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit</th>\n",
       "      <td>41537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>39517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>35162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>30731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>30476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pleas</th>\n",
       "      <td>29969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>29322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frequency\n",
       "articl         74137\n",
       "page           57083\n",
       "wikipedia      46144\n",
       "edit           41537\n",
       "talk           39517\n",
       "use            35162\n",
       "one            30731\n",
       "like           30476\n",
       "pleas          29969\n",
       "would          29322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(135213, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parsing into a dataframe\n",
    "bow_df = pd.DataFrame.from_dict(bag_o_words,\n",
    "                                orient = 'index',\n",
    "                                columns = ['frequency']\n",
    "                                ).sort_values(\n",
    "                                    by = 'frequency',\n",
    "                                    ascending = False)\n",
    "\n",
    "display(bow_df.head(10), bow_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working on Dataframe itself\n",
    "Previous cells worked on extracted rows within the `txt_blab` dataframe, therefore just piling words on top of words aimlessly, though it can be considered some sort of analysis of word count if need be.\n",
    "\n",
    "Following this cell onwards, similar work will be done on the rows *within* the dataframe, instead of completely extracting.\n",
    "\n",
    "Task at hand, later down the line, is to classify the data if it's toxic or normal discussion.\n",
    "\n",
    "Hence collapsing the columns beyond `toxic` onto it through sum, if it's not $0$ it will be considered toxic, with a variable degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collepsing the column values onto toxic\n",
    "txt_blab['toxic'] = txt_blab['severe_toxic'] + txt_blab['obscene'] + txt_blab['threat'] + txt_blab['insult'] + txt_blab['identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0  Explanation  Why the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"  More  I can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.124108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.513515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.124108\n",
       "std         0.513515\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dropping collapsed columns\n",
    "collapsed_cols = ['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "txt_blab.drop(columns = collapsed_cols, inplace = True)\n",
    "\n",
    "display(txt_blab.head(), txt_blab.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, from the collapse, values larger than 1 arose, therefore altering their value to 0 would be optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic\n",
       "0  Explanation  Why the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"  More  I can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.066171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.248582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic\n",
       "count  159571.000000\n",
       "mean        0.066171\n",
       "std         0.248582\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "txt_blab['toxic'] = np.where(txt_blab['toxic'] > 1, txt_blab['toxic'] - (txt_blab['toxic'] - 1), txt_blab['toxic'])\n",
    "\n",
    "display(txt_blab.head(), txt_blab.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the english words\n",
    "# To avoid random words later\n",
    "#nltk.download('words')\n",
    "ENGLISH_WORDS = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Explanation, Why, the, edits, made, under, my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, He, matches, this, background, colour, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Hey, man, really, not, trying, to, edit, war,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[More, can, make, any, real, suggestions, on, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>[You, sir, are, my, hero, Any, chance, you, re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  \\\n",
       "0  Explanation  Why the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"  More  I can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [Explanation, Why, the, edits, made, under, my...  \n",
       "1  [aww, He, matches, this, background, colour, s...  \n",
       "2  [Hey, man, really, not, trying, to, edit, war,...  \n",
       "3  [More, can, make, any, real, suggestions, on, ...  \n",
       "4  [You, sir, are, my, hero, Any, chance, you, re...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing words per row\n",
    "txt_blab['tokens'] = [regexp_tokenize(row, upper_lower_words) for row in txt_blab['comment_text']]\n",
    "\n",
    "txt_blab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change words within a list to be lowercase\n",
    "def list_lower(word_list):\n",
    "    return [word.lower() for word in word_list]\n",
    "\n",
    "# Remove stopwords from a list of tokens\n",
    "def stopwordless(word_list):\n",
    "    return [word for word in word_list if word not in ENGLISH_STOPWORDS]\n",
    "\n",
    "# Stem tokens within a list\n",
    "def list_stem(word_list):\n",
    "    return [snowball.stem(token) for token in word_list]\n",
    "\n",
    "# Removing words that do not belong to the english language\n",
    "# Or completely random words..\n",
    "def englishify(token_list):\n",
    "    return [word for word in token_list if word in ENGLISH_WORDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[explan, edit, made, usernam, hardcor, metalli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[aww, he, matches, this, background, colour, s...</td>\n",
       "      <td>[aww, match, background, colour, seem, stuck, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, not, trying, to, edit, war,...</td>\n",
       "      <td>[hey, man, realli, tri, edit, war, guy, consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[more, can, make, any, real, suggestions, on, ...</td>\n",
       "      <td>[make, real, suggest, improv, wonder, section,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chanc, rememb, page]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  \\\n",
       "0  Explanation  Why the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"  More  I can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [aww, he, matches, this, background, colour, s...   \n",
       "2  [hey, man, really, not, trying, to, edit, war,...   \n",
       "3  [more, can, make, any, real, suggestions, on, ...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                               stems  \n",
       "0  [explan, edit, made, usernam, hardcor, metalli...  \n",
       "1  [aww, match, background, colour, seem, stuck, ...  \n",
       "2  [hey, man, realli, tri, edit, war, guy, consta...  \n",
       "3  [make, real, suggest, improv, wonder, section,...  \n",
       "4                   [sir, hero, chanc, rememb, page]  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower casing each word\n",
    "txt_blab['tokens'] = [list_lower(row) for row in txt_blab['tokens']]\n",
    "\n",
    "txt_blab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, why, the, made, under, my, fan, ...</td>\n",
       "      <td>[explan, edit, made, usernam, hardcor, metalli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[he, this, background, colour, seemingly, stuc...</td>\n",
       "      <td>[aww, match, background, colour, seem, stuck, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, not, trying, to, edit, war,...</td>\n",
       "      <td>[hey, man, realli, tri, edit, war, guy, consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[more, can, make, any, real, on, improvement, ...</td>\n",
       "      <td>[make, real, suggest, improv, wonder, section,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chanc, rememb, page]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  \\\n",
       "0  Explanation  Why the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"  More  I can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [explanation, why, the, made, under, my, fan, ...   \n",
       "1  [he, this, background, colour, seemingly, stuc...   \n",
       "2  [hey, man, really, not, trying, to, edit, war,...   \n",
       "3  [more, can, make, any, real, on, improvement, ...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                               stems  \n",
       "0  [explan, edit, made, usernam, hardcor, metalli...  \n",
       "1  [aww, match, background, colour, seem, stuck, ...  \n",
       "2  [hey, man, realli, tri, edit, war, guy, consta...  \n",
       "3  [make, real, suggest, improv, wonder, section,...  \n",
       "4                   [sir, hero, chanc, rememb, page]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_blab['tokens'] = [englishify(row) for row in txt_blab['tokens']]\n",
    "\n",
    "txt_blab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, why, the, made, under, my, fan, ...</td>\n",
       "      <td>[explan, made, fan, closur, gas, new, york, pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[he, this, background, colour, seemingly, stuc...</td>\n",
       "      <td>[background, colour, seem, stuck, thank, talk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, really, not, trying, to, edit, war,...</td>\n",
       "      <td>[hey, man, realli, tri, edit, war, guy, consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[more, can, make, any, real, on, improvement, ...</td>\n",
       "      <td>[make, real, improv, section, statist, later, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[sir, hero, chanc, rememb, page]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  \\\n",
       "0  Explanation  Why the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"  More  I can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [explanation, why, the, made, under, my, fan, ...   \n",
       "1  [he, this, background, colour, seemingly, stuc...   \n",
       "2  [hey, man, really, not, trying, to, edit, war,...   \n",
       "3  [more, can, make, any, real, on, improvement, ...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                               stems  \n",
       "0  [explan, made, fan, closur, gas, new, york, pl...  \n",
       "1     [background, colour, seem, stuck, thank, talk]  \n",
       "2  [hey, man, realli, tri, edit, war, guy, consta...  \n",
       "3  [make, real, improv, section, statist, later, ...  \n",
       "4                   [sir, hero, chanc, rememb, page]  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_blab['stems'] = [list_stem(stopwordless(row)) for row in txt_blab['tokens']]\n",
    "\n",
    "txt_blab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a dummy tokenizer in order to make the vectorizer work\n",
    "# returns what it takes (We already have tokenized sentences)\n",
    "def identity_tokenizer(text):\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer with custom params\n",
    "tfidf_vec = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase = False)\n",
    "\n",
    "# Fit the vectorizer\n",
    "# Fitting on Unstemmed words (idk not sure)\n",
    "transformFit = tfidf_vec.fit_transform(txt_blab.iloc[:10000, 3])\n",
    "\n",
    "# Storing the tfidf values\n",
    "tfidf_vals = pd.DataFrame(transformFit.toarray().transpose(), tfidf_vec.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0     1     2     3     4     5     6     7     8     9     ...  \\\n",
      "aa         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "aardvark   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "aba        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "aback      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "abandon    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "zodiac     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "zone       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "zoo        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "zoolog     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "zoom       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
      "\n",
      "          9990  9991  9992  9993  9994  9995  9996  9997  9998  9999  \n",
      "aa         0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "aardvark   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "aba        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "aback      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "abandon    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "zodiac     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "zone       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "zoo        0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "zoolog     0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "zoom       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[9927 rows x 10000 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
