{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blabber Cleaning\n",
    "#### (By: Mark Ehab Aziz)\n",
    "#### (Built Under: Python 3.11.4)\n",
    "Filtering out and cleaning text data.\n",
    "As tasked inside the 'to do.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd     # Loading Data\n",
    "import re\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize     # To Tokenize Words\n",
    "from nltk.stem import PorterStemmer         # Stemming words\n",
    "from nltk.stem import WordNetLemmatizer     # Lemmatizing words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into kernel\n",
    "# Using two methods (As stated in my previous projects)\n",
    "# 1. Path working within my git repo\n",
    "blab = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# 2. Path when data is within the same folder\n",
    "#blab = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Using `.head(n)` to show the first $n^{th}$ rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining n rows to see\n",
    "n = 5\n",
    "\n",
    "# Showing head\n",
    "blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated by our todo list, we are only tasked with cleaning of the text, so we'll be focusing on `comment_text`.\n",
    "\n",
    "Referring to our todo list once again, we will be dropping `id`, `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`; as we are not concerned with classifying the sentiment or the meaning behind any of the comments.\n",
    "\n",
    "Reminder for what to be done:\n",
    "- Read Text\n",
    "- Clean Text (Capitalisation, punctuation)\n",
    "- Remove Stop Words\n",
    "- Tokenization\n",
    "- Stemming\n",
    "\n",
    "Under no aforementioned task will we be using the columns I have mentioned to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation\\r\\nWhy the edits made under my use...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining list of columns to be dropped\n",
    "col_droppable = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Dropping\n",
    "txt_blab = blab.drop(columns = col_droppable)\n",
    "\n",
    "# Viewing\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing '\\n' '\\r' '\\t' from every line-kinda\n",
    "txt_blab.replace(r'[\\r\\n\\t]', ' ', regex = True, inplace=True)\n",
    "\n",
    "# Removing URLs (Standard URL Scheme, There still exist instances\n",
    "# of just 'https' or 'http' randomly written, they will just be\n",
    "# treated like normal words and tokenized as the rest)\n",
    "txt_blab.replace(r'http://\\S+|https://\\S+', '', regex = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Above Sentences\n",
    "Using NLTK and Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regex patterns\n",
    "# Match words starting with Uppercase letters\n",
    "upper_words = r\"([A-Z])\\w+\"\n",
    "\n",
    "# Match Words that start with either Upper/lowercase letters\n",
    "upper_lower_words = r\"[A-Za-z]\\w+\"\n",
    "\n",
    "# Match Emails\n",
    "email_pattern = r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,4}\\b\"\n",
    "\n",
    "# Match URLs\n",
    "url_pattern = r\"(http|ftp|https):\\/\\/([\\w+?\\.\\w+])+([a-zA-Z0-9\\~\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)_\\-\\=\\+\\\\\\/\\?\\.\\:\\;\\'\\,]*)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a bag of words list, to hold tokens of each word\n",
    "# Probably better to use a dictionary if we care about count???\n",
    "# Still gotta access every token and change to lower\n",
    "# Also still gotta make it so that i can stem and remove some other special characters\n",
    "# Progress?????\n",
    "token_per_row = []\n",
    "\n",
    "# Start and finish indecies of iterator\n",
    "# Bound to become the length of the file eventually\n",
    "# I really dispise this\n",
    "for i in range(0, 50):\n",
    "    # Grab string fully from dataframe\n",
    "    line = txt_blab.iloc[i,0]\n",
    "\n",
    "    # Append list of tokens\n",
    "    token_per_row.append(regexp_tokenize(line, upper_lower_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase every word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
