{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blabber Cleaning\n",
    "#### (By: Mark Ehab Aziz)\n",
    "#### (Built Under: Python 3.11.4)\n",
    "Filtering out and cleaning text data.\n",
    "As tasked inside the 'to do.txt'.\n",
    "\n",
    "Ensure the presence of nltk package using `pip install nltk`.\n",
    "\n",
    "Following usage of nltk should not require further dependencies than the basic install and stopwords.\n",
    "\n",
    "If anything; Ensure presence of `nltk`, the download for stopwords is within the cells and will download automatically should it not detect any instance of predownloaded stopwords for itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd                         # Loading Data\n",
    "import nltk                                 # Required to download stopwords set\n",
    "from nltk.corpus import stopwords           # Load Stopwords\n",
    "from nltk.tokenize import regexp_tokenize   # To Tokenize words with Regex Expressions\n",
    "from nltk.stem import PorterStemmer         # Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data into environment\n",
    "# Using two methods (As stated in my previous projects)\n",
    "# 1. Path working within my git repo\n",
    "blab = pd.read_csv(\"../dataset/train.csv\")\n",
    "\n",
    "# 2. Path when data is within the same folder\n",
    "#blab = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "Using `.head(n)` to show the first $n^{th}$ rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\r\\nWhy the edits made under my use...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\r\\nMore\\r\\nI can't make any real suggestions...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining n rows to see\n",
    "n = 5\n",
    "\n",
    "# Showing head\n",
    "blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated by our todo list, we are only tasked with cleaning of the text, so we'll be focusing on `comment_text`.\n",
    "\n",
    "Referring to our todo list once again, we will be dropping `id`, `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`; as we are not concerned with classifying the sentiment or the meaning behind any of the comments.\n",
    "\n",
    "Reminder for what to be done:\n",
    "- Read Text\n",
    "- Clean Text (Capitalisation, punctuation)\n",
    "- Remove Stop Words\n",
    "- Tokenization\n",
    "- Stemming\n",
    "\n",
    "Under no aforementioned task will we be using the columns I have mentioned to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation\\r\\nWhy the edits made under my use...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"\\r\\nMore\\r\\nI can't make any real suggestions...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining list of columns to be dropped\n",
    "col_droppable = [\"id\", \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "# Dropping\n",
    "txt_blab = blab.drop(columns = col_droppable)\n",
    "\n",
    "# Viewing\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation  Why the edits made under my usern...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"  More  I can't make any real suggestions on ...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing '\\n' '\\r' '\\t' from every line\n",
    "txt_blab.replace(r'[\\r\\n\\t]', ' ', regex = True, inplace=True)\n",
    "\n",
    "# As noted, there are no escape characters for spaces, as new line or tab\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Above Sentences\n",
    "Using the NLTK library for Python; will be copy-pasting or creating patterns that are enough to extract words, starting with either upper or lower case letters.\n",
    "\n",
    "This may violate the order of operations specified in the ToDo list, as cleaning data preceeds tokenization, but `regexp_tokenize()` takes care of both steps anyway, through just matching what is specified within the regex, as only 'Latin Alphabet' ranges are specified (`A-Za-z`), it will automatically unmatch any special character or non-alphabet character, ignores punctuation as well.\n",
    "\n",
    "Will also be removing the URLs as specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regex patterns\n",
    "# Match words starting with Uppercase letters\n",
    "upper_words = r\"([A-Z])\\w+\"\n",
    "\n",
    "# Match Words that start with either Upper/lowercase letters\n",
    "upper_lower_words = r\"[A-Za-z]\\w+\"\n",
    "\n",
    "# Match URLs\n",
    "url_pattern = r\"(http|ftp|https):\\/\\/([\\w+?\\.\\w+])+([a-zA-Z0-9\\~\\!\\@\\#\\$\\%\\^\\&\\*\\(\\)_\\-\\=\\+\\\\\\/\\?\\.\\:\\;\\'\\,]*)?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation  Why the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"  More  I can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text\n",
       "0  Explanation  Why the edits made under my usern...\n",
       "1  D'aww! He matches this background colour I'm s...\n",
       "2  Hey man, I'm really not trying to edit war. It...\n",
       "3  \"  More  I can't make any real suggestions on ...\n",
       "4  You, sir, are my hero. Any chance you remember..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing URLs (Standard URL Scheme, There still exist instances\n",
    "# of just 'https' or 'http' randomly written, they will just be\n",
    "# treated like normal words and tokenized as the rest)\n",
    "txt_blab.replace(url_pattern, '', regex = True, inplace = True)\n",
    "\n",
    "txt_blab.head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "Iterating over each row of the given textual data, accessing as a string instead of a usual row in order to yield the full entry.\n",
    "\n",
    "Using regex to tokenize words by matching pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a list of tokens, to hold tokens of each entry\n",
    "# Probably better to use a dictionary if we care about count (?)\n",
    "# Still have to access every token and change to lower (Taken care of in flat list)\n",
    "token_per_row = []\n",
    "\n",
    "# Start and finish indecies of iterator\n",
    "# Bound to become the length of the file eventually\n",
    "for i in range(50):\n",
    "    # Grab string fully from dataframe\n",
    "    line = txt_blab.iloc[i,0]\n",
    "\n",
    "    # Append list of tokens\n",
    "    # 2D list of lists; each containing tokens of each row\n",
    "    token_per_row.append(regexp_tokenize(line, upper_lower_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 2D List of Lists\n",
    "# n^2 operation but still gets the job done\n",
    "# Would be better to flatten as soon as\n",
    "# the tokens are fresh out the tokenizer\n",
    "def flatten(list_o_lists):\n",
    "    # init flat list\n",
    "    flat = []\n",
    "\n",
    "    # Loop over every list within the list\n",
    "    for sublist in list_o_lists:\n",
    "        # Loop over every token within the sublist\n",
    "        # being iterated on\n",
    "        for token in sublist:\n",
    "            # Append token to flat list\n",
    "            flat.append(token)\n",
    "\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'weren', 'vandalisms', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'don', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'retired', 'now', 'aww', 'He', 'matches', 'this', 'background', 'colour', 'seemingly', 'stuck', 'with', 'Thanks', 'talk', 'January', 'UTC', 'Hey', 'man', 'really', 'not', 'trying', 'to', 'edit', 'war', 'It', 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page', 'He', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info', 'More', 'can', 'make', 'any', 'real', 'suggestions', 'on', 'improvement', 'wondered', 'if', 'the', 'section', 'statistics', 'should', 'be', 'later', 'on', 'or', 'subsection', 'of', 'types', 'of', 'accidents', 'think', 'the', 'references', 'may', 'need', 'tidying', 'so', 'that', 'they', 'are', 'all', 'in', 'the', 'exact', 'same', 'format', 'ie', 'date', 'format', 'etc', 'can', 'do', 'that', 'later', 'on', 'if', 'no', 'one', 'else', 'does', 'first', 'if', 'you', 'have', 'any', 'preferences', 'for', 'formatting', 'style', 'on', 'references', 'or', 'want', 'to', 'do', 'it', 'yourself', 'please', 'let', 'me', 'know', 'There', 'appears', 'to', 'be', 'backlog', 'on', 'articles', 'for', 'review', 'so', 'guess', 'there', 'may', 'be', 'delay', 'until', 'reviewer', 'turns', 'up', 'It', 'listed', 'in', 'the', 'relevant', 'form', 'eg', 'Wikipedia', 'Good_article_nominations', 'Transport', 'You', 'sir', 'are', 'my', 'hero', 'Any', 'chance', 'you', 'remember', 'what', 'page', 'that', 'on', 'Congratulations', 'from', 'me', 'as', 'well', 'use', 'the', 'tools', 'well', 'talk', 'COCKSUCKER', 'BEFORE', 'YOU', 'PISS', 'AROUND', 'ON', 'MY', 'WORK', 'Your', 'vandalism', 'to', 'the', 'Matt', 'Shirvington', 'article', 'has', 'been', 'reverted', 'Please', 'don', 'do', 'it', 'again', 'or', 'you', 'will', 'be', 'banned', 'Sorry', 'if', 'the', 'word', 'nonsense', 'was', 'offensive', 'to', 'you', 'Anyway', 'not', 'intending', 'to', 'write', 'anything', 'in', 'the', 'article', 'wow', 'they', 'would', 'jump', 'on', 'me', 'for', 'vandalism', 'merely', 'requesting', 'that', 'it', 'be', 'more', 'encyclopedic', 'so', 'one', 'can', 'use', 'it', 'for', 'school', 'as', 'reference', 'have', 'been', 'to', 'the', 'selective', 'breeding', 'page', 'but', 'it', 'almost', 'stub', 'It', 'points', 'to', 'animal', 'breeding', 'which', 'is', 'short', 'messy', 'article', 'that', 'gives', 'you', 'no', 'info', 'There', 'must', 'be', 'someone', 'around', 'with', 'expertise', 'in', 'eugenics', 'alignment', 'on', 'this', 'subject', 'and', 'which', 'are', 'contrary', 'to', 'those', 'of', 'DuLithgow', 'Fair', 'use', 'rationale', 'for', 'Image', 'Wonju', 'jpg', 'Thanks', 'for', 'uploading', 'Image', 'Wonju', 'jpg', 'notice', 'the', 'image', 'page', 'specifies', 'that', 'the', 'image', 'is', 'being', 'used', 'under', 'fair', 'use', 'but', 'there', 'is', 'no', 'explanation', 'or', 'rationale', 'as', 'to', 'why', 'its', 'use', 'in', 'Wikipedia', 'articles', 'constitutes', 'fair', 'use', 'In', 'addition', 'to', 'the', 'boilerplate', 'fair', 'use', 'template', 'you', 'must', 'also', 'write', 'out', 'on', 'the', 'image', 'description', 'page', 'specific', 'explanation', 'or', 'rationale', 'for', 'why', 'using', 'this', 'image', 'in', 'each', 'article', 'is', 'consistent', 'with', 'fair', 'use', 'Please', 'go', 'to', 'the', 'image', 'description', 'page', 'and', 'edit', 'it', 'to', 'include', 'fair', 'use', 'rationale', 'If', 'you', 'have', 'uploaded', 'other', 'fair', 'use', 'media', 'consider', 'checking', 'that', 'you', 'have', 'specified', 'the', 'fair', 'use', 'rationale', 'on', 'those', 'pages', 'too', 'You', 'can', 'find', 'list', 'of', 'image', 'pages', 'you', 'have', 'edited', 'by', 'clicking', 'on', 'the', 'my', 'contributions', 'link', 'it', 'is', 'located', 'at', 'the', 'very', 'top', 'of', 'any', 'Wikipedia', 'page', 'when', 'you', 'are', 'logged', 'in', 'and', 'then', 'selecting', 'Image', 'from', 'the', 'dropdown', 'box', 'Note', 'that', 'any', 'fair', 'use', 'images', 'uploaded', 'after', 'May', 'and', 'lacking', 'such', 'an', 'explanation', 'will', 'be', 'deleted', 'one', 'week', 'after', 'they', 'have', 'been', 'uploaded', 'as', 'described', 'on', 'criteria', 'for', 'speedy', 'deletion', 'If', 'you', 'have', 'any', 'questions', 'please', 'ask', 'them', 'at', 'the', 'Media', 'copyright', 'questions', 'page', 'Thank', 'you', 'talk', 'contribs', 'Unspecified', 'source', 'for', 'Image', 'Wonju', 'jpg', 'Thanks', 'for', 'uploading', 'Image', 'Wonju', 'jpg', 'noticed', 'that', 'the', 'file', 'description', 'page', 'currently', 'doesn', 'specify', 'who', 'created', 'the', 'content', 'so', 'the', 'copyright', 'status', 'is', 'unclear', 'If', 'you', 'did', 'not', 'create', 'this', 'file', 'yourself', 'then', 'you', 'will', 'need', 'to', 'specify', 'the', 'owner', 'of', 'the', 'copyright', 'If', 'you', 'obtained', 'it', 'from', 'website', 'then', 'link', 'to', 'the', 'website', 'from', 'which', 'it', 'was', 'taken', 'together', 'with', 'restatement', 'of', 'that', 'website', 'terms', 'of', 'use', 'of', 'its', 'content', 'is', 'usually', 'sufficient', 'information', 'However', 'if', 'the', 'copyright', 'holder', 'is', 'different', 'from', 'the', 'website', 'publisher', 'then', 'their', 'copyright', 'should', 'also', 'be', 'acknowledged', 'As', 'well', 'as', 'adding', 'the', 'source', 'please', 'add', 'proper', 'copyright', 'licensing', 'tag', 'if', 'the', 'file', 'doesn', 'have', 'one', 'already', 'If', 'you', 'created', 'took', 'the', 'picture', 'audio', 'or', 'video', 'then', 'the', 'tag', 'can', 'be', 'used', 'to', 'release', 'it', 'under', 'the', 'GFDL', 'If', 'you', 'believe', 'the', 'media', 'meets', 'the', 'criteria', 'at', 'Wikipedia', 'Fair', 'use', 'use', 'tag', 'such', 'as', 'or', 'one', 'of', 'the', 'other', 'tags', 'listed', 'at', 'Wikipedia', 'Image', 'copyright', 'tags', 'Fair', 'use', 'See', 'Wikipedia', 'Image', 'copyright', 'tags', 'for', 'the', 'full', 'list', 'of', 'copyright', 'tags', 'that', 'you', 'can', 'use', 'If', 'you', 'have', 'uploaded', 'other', 'files', 'consider', 'checking', 'that', 'you', 'have', 'specified', 'their', 'source', 'and', 'tagged', 'them', 'too', 'You', 'can', 'find', 'list', 'of', 'files', 'you', 'have', 'uploaded', 'by', 'following', 'this', 'link', 'Unsourced', 'and', 'untagged', 'images', 'may', 'be', 'deleted', 'one', 'week', 'after', 'they', 'have', 'been', 'tagged', 'as', 'described', 'on', 'criteria', 'for', 'speedy', 'deletion', 'If', 'the', 'image', 'is', 'copyrighted', 'under', 'non', 'free', 'license', 'per', 'Wikipedia', 'Fair', 'use', 'then', 'the', 'image', 'will', 'be', 'deleted', 'hours', 'after', 'If', 'you', 'have', 'any', 'questions', 'please', 'ask', 'them', 'at', 'the', 'Media', 'copyright', 'questions', 'page', 'Thank', 'you', 'talk', 'contribs', 'bbq', 'be', 'man', 'and', 'lets', 'discuss', 'it', 'maybe', 'over', 'the', 'phone', 'Hey', 'what', 'is', 'it', 'talk', 'What', 'is', 'it', 'an', 'exclusive', 'group', 'of', 'some', 'WP', 'TALIBANS', 'who', 'are', 'good', 'at', 'destroying', 'self', 'appointed', 'purist', 'who', 'GANG', 'UP', 'any', 'one', 'who', 'asks', 'them', 'questions', 'abt', 'their', 'ANTI', 'SOCIAL', 'and', 'DESTRUCTIVE', 'non', 'contribution', 'at', 'WP', 'Ask', 'Sityush', 'to', 'clean', 'up', 'his', 'behavior', 'than', 'issue', 'me', 'nonsensical', 'warnings', 'Before', 'you', 'start', 'throwing', 'accusations', 'and', 'warnings', 'at', 'me', 'lets', 'review', 'the', 'edit', 'itself', 'making', 'ad', 'hominem', 'attacks', 'isn', 'going', 'to', 'strengthen', 'your', 'argument', 'it', 'will', 'merely', 'make', 'it', 'look', 'like', 'you', 'are', 'abusing', 'your', 'power', 'as', 'an', 'admin', 'Now', 'the', 'edit', 'itself', 'is', 'relevant', 'this', 'is', 'probably', 'the', 'single', 'most', 'talked', 'about', 'event', 'int', 'he', 'news', 'as', 'of', 'late', 'His', 'absence', 'is', 'notable', 'since', 'he', 'is', 'the', 'only', 'living', 'ex', 'president', 'who', 'did', 'not', 'attend', 'That', 'certainly', 'more', 'notable', 'than', 'his', 'dedicating', 'an', 'aircracft', 'carrier', 'intend', 'to', 'revert', 'this', 'edit', 'in', 'hopes', 'of', 'attracting', 'the', 'attention', 'of', 'an', 'admin', 'that', 'is', 'willing', 'to', 'look', 'at', 'the', 'issue', 'itself', 'and', 'not', 'throw', 'accusations', 'around', 'quite', 'so', 'liberally', 'Perhaps', 'if', 'you', 'achieve', 'level', 'of', 'civility', 'where', 'you', 'can', 'do', 'this', 'we', 'can', 'have', 'rational', 'discussion', 'on', 'the', 'topic', 'and', 'resolve', 'the', 'matter', 'peacefully', 'Oh', 'and', 'the', 'girl', 'above', 'started', 'her', 'arguments', 'with', 'me', 'She', 'stuck', 'her', 'nose', 'where', 'it', 'doesn', 'belong', 'believe', 'the', 'argument', 'was', 'between', 'me', 'and', 'Yvesnimmo', 'But', 'like', 'said', 'the', 'situation', 'was', 'settled', 'and', 'apologized', 'Thanks', 'Juelz', 'Santanas', 'Age', 'In', 'Juelz', 'Santana', 'was', 'years', 'old', 'then', 'came', 'February', 'th', 'which', 'makes', 'Juelz', 'turn', 'making', 'songs', 'with', 'The', 'Diplomats', 'The', 'third', 'neff', 'to', 'be', 'signed', 'to', 'Cam', 'label', 'under', 'Roc', 'Fella', 'In', 'he', 'was', 'years', 'old', 'coming', 'out', 'with', 'his', 'own', 'singles', 'Santana', 'Town', 'and', 'Down', 'So', 'yes', 'he', 'is', 'born', 'in', 'He', 'really', 'is', 'how', 'could', 'he', 'be', 'older', 'then', 'Lloyd', 'Banks', 'And', 'how', 'could', 'he', 'be', 'when', 'his', 'birthday', 'passed', 'The', 'homie', 'neff', 'is', 'years', 'old', 'Juelz', 'death', 'god', 'forbid', 'if', 'your', 'thinking', 'about', 'that', 'equals', 'Go', 'to', 'your', 'caculator', 'and', 'stop', 'changing', 'his', 'year', 'of', 'birth', 'My', 'god', 'Bye', 'Don', 'look', 'come', 'or', 'think', 'of', 'comming', 'back', 'Tosser', 'REDIRECT', 'Talk', 'Voydan', 'Pop', 'Georgiev', 'Chernodrinski', 'The', 'Mitsurugi', 'point', 'made', 'no', 'sense', 'why', 'not', 'argue', 'to', 'include', 'Hindi', 'on', 'Ryo', 'Sakazaki', 'page', 'to', 'include', 'more', 'information', 'Don', 'mean', 'to', 'bother', 'you', 'see', 'that', 'you', 're', 'writing', 'something', 'regarding', 'removing', 'anything', 'posted', 'here', 'and', 'if', 'you', 'do', 'oh', 'well', 'but', 'if', 'not', 'and', 'you', 'can', 'acctually', 'discuss', 'this', 'with', 'me', 'then', 'even', 'better', 'like', 'to', 'ask', 'you', 'to', 'take', 'closer', 'look', 'at', 'the', 'Premature', 'wrestling', 'deaths', 'catagory', 'and', 'the', 'men', 'listed', 'in', 'it', 'surely', 'these', 'men', 'belong', 'together', 'in', 'some', 'catagory', 'Is', 'there', 'anything', 'that', 'you', 'think', 'we', 'can', 'do', 'with', 'the', 'catagory', 'besides', 'delting', 'it', 'Regarding', 'your', 'recent', 'edits', 'Once', 'again', 'please', 'read', 'WP', 'FILMPLOT', 'before', 'editing', 'any', 'more', 'film', 'articles', 'Your', 'edits', 'are', 'simply', 'not', 'good', 'with', 'entirely', 'too', 'many', 'unnecessary', 'details', 'and', 'very', 'bad', 'writing', 'Please', 'stop', 'before', 'you', 'do', 'further', 'damage', 'The', 'Good', 'to', 'know', 'About', 'me', 'yeah', 'studying', 'now', 'Deepu', 'Snowflakes', 'are', 'NOT', 'always', 'symmetrical', 'Under', 'Geometry', 'it', 'is', 'stated', 'that', 'snowflake', 'always', 'has', 'six', 'symmetric', 'arms', 'This', 'assertion', 'is', 'simply', 'not', 'true', 'According', 'to', 'Kenneth', 'Libbrecht', 'The', 'rather', 'unattractive', 'irregular', 'crystals', 'are', 'by', 'far', 'the', 'most', 'common', 'variety', 'Someone', 'really', 'need', 'to', 'take', 'look', 'at', 'his', 'site', 'and', 'get', 'FACTS', 'off', 'of', 'it', 'because', 'still', 'see', 'decent', 'number', 'of', 'falsities', 'on', 'this', 'page', 'forgive', 'me', 'Im', 'new', 'at', 'this', 'and', 'dont', 'want', 'to', 'edit', 'anything', 'The', 'Signpost', 'September', 'Read', 'this', 'Signpost', 'in', 'full', 'Single', 'page', 'Unsubscribe', 'Re', 'considering', 'st', 'paragraph', 'edit', 'don', 'understand', 'the', 'reasons', 'for', 'recent', 'edit', 'of', 'this', 'article', 'not', 'that', 'sure', 'that', 'the', 'data', 'are', 'necessarily', 'wrong', 'Rather', 'persuaded', 'that', 'the', 'strategy', 'of', 'introducing', 'academic', 'honors', 'in', 'the', 'first', 'paragraph', 'is', 'an', 'unhelpful', 'approach', 'to', 'this', 'specific', 'subject', 'note', 'that', 'articles', 'about', 'other', 'sitting', 'Justices', 'have', 'been', 'similarly', 'enhanced', 'and', 'also', 'believe', 'those', 'changes', 'are', 'no', 'improvement', 'In', 'support', 'of', 'my', 'view', 'that', 'this', 'edit', 'should', 'be', 'reverted', 'would', 'invite', 'anyone', 'to', 're', 'visit', 'articles', 'written', 'about', 'the', 'following', 'pairs', 'of', 'jurists', 'A1', 'Benjamin', 'Cardozo', 'A2', 'Learned', 'Hand', 'B1', 'John', 'Marshall', 'Harlan', 'B2', 'John', 'Marshall', 'Harlan', 'II', 'The', 'question', 'becomes', 'Would', 'the', 'current', 'version', 'of', 'the', 'Wikipedia', 'article', 'about', 'any', 'one', 'of', 'them', 'or', 'either', 'pair', 'be', 'improved', 'by', 'academic', 'credentials', 'in', 'the', 'introductory', 'paragraph', 'think', 'not', 'Perhaps', 'it', 'helps', 'to', 'repeat', 'wry', 'argument', 'Kathleen', 'Sullivan', 'of', 'Stanford', 'Law', 'makes', 'when', 'she', 'suggests', 'that', 'some', 'on', 'the', 'Harvard', 'Law', 'faculty', 'wonder', 'how', 'Antonin', 'Scalia', 'avoided', 'learning', 'what', 'others', 'have', 'managed', 'to', 'grasp', 'about', 'the', 'processes', 'of', 'judging', 'would', 'hope', 'this', 'anecdote', 'gently', 'illustrates', 'the', 'point', 'Less', 'humorous', 'but', 'an', 'even', 'stronger', 'argument', 'is', 'the', 'one', 'Clarence', 'Thomas', 'makes', 'when', 'he', 'mentions', 'wanting', 'to', 'return', 'his', 'law', 'degree', 'to', 'Yale', 'At', 'minimum', 'questioning', 'this', 'edit', 'It', 'deserves', 'to', 'be', 'reconsidered', 'Radial', 'symmetry', 'Several', 'now', 'extinct', 'lineages', 'included', 'in', 'the', 'Echinodermata', 'were', 'bilateral', 'such', 'as', 'Homostelea', 'or', 'even', 'asymmetrical', 'such', 'as', 'Cothurnocystis', 'Stylophora', 'There', 'no', 'need', 'to', 'apologize', 'Wikipedia', 'article', 'is', 'made', 'for', 'reconciling', 'knowledge', 'about', 'subject', 'from', 'different', 'sources', 'and', 'you', 've', 'done', 'history', 'studies', 'and', 'not', 'archaeology', 'studies', 'guess', 'could', 'scan', 'the', 'page', 'mail', 'it', 'to', 'you', 'and', 'then', 'you', 'could', 'ask', 'someone', 'to', 'translate', 'the', 'page', 'Yes', 'because', 'the', 'mother', 'of', 'the', 'child', 'in', 'the', 'case', 'against', 'Michael', 'Jackson', 'was', 'studied', 'in', 'here', 'motives', 'and', 'reasonings', 'and', 'judged', 'upon', 'her', 'character', 'just', 'as', 'harshly', 'as', 'Wacko', 'Jacko', 'himself', 'Don', 'tell', 'me', 'to', 'ignore', 'it', 'and', 'incriminate', 'myself', 'am', 'going', 'to', 'continue', 'refuting', 'the', 'bullshit', 'that', 'Jayjg', 'keeps', 'throwing', 'at', 'me', 'Jun', 'UTC', 'Ok', 'But', 'it', 'will', 'take', 'bit', 'of', 'work', 'but', 'can', 'quite', 'picture', 'it', 'Do', 'you', 'have', 'an', 'example', 'can', 'base', 'it', 'on', 'the', 'Duck', 'barnstar', 'for', 'you', 'The', 'Real', 'Life', 'Barnstar', 'lets', 'us', 'be', 'the', 'stars', 'How', 'could', 'post', 'before', 'the', 'block', 'expires', 'The', 'funny', 'thing', 'is', 'you', 'think', 'being', 'uncivil', 'Not', 'sure', 'about', 'heading', 'of', 'Fight', 'for', 'Freedom', 'what', 'will', 'it', 'contain', 'Praise', 'looked', 'at', 'this', 'article', 'about', 'months', 'ago', 'much', 'improved', 'was', 'able', 'to', 'post', 'the', 'above', 'list', 'so', 'quickly', 'because', 'already', 'had', 'it', 'in', 'text', 'file', 'in', 'my', 'hard', 'drive', 've', 'been', 'meaning', 'to', 'get', 'around', 'to', 'updating', 'the', 'sound', 'list', 'for', 'some', 'time', 'now', 'As', 'far', 'as', 'generating', 'interest', 've', 'spent', 'four', 'years', 'trying', 'to', 'drum', 'up', 'more', 'interest', 'in', 'freely', 'licensed', 'full', 'length', 'classical', 'music', 'Unfortunately', 'my', 'attempts', 'failed', 'still', 'effectively', 'the', 'only', 'one', 'who', 'does', 'it', 'The', 'classical', 'music', 'wikiproject', 'was', 'not', 'interested', 'Wikipedia_talk', 'WikiProject_Classical_music', 'Archive_5', 'Need_help', 'Wikipedia_talk', 'WikiProject_Music', 'Archive_3', 'I_could_use_some_helpWikipedia_talk', 'WikiProject_Music', 'Archive_2', 'Raulbot', 'C_and_the_music_list', 'So', 'really', 'had', 'given', 'up', 'trying', 'to', 'interest', 'others', 'The', 'sound', 'list', 'was', 'featured', 'on', 'digg', 'while', 'back', 'It', 'got', 'diggs', 'which', 'is', 'IMO', 'very', 'impressive', 'Well', 'not', 'before', 'the', 'process', 'but', 'before', 'how', 'we', 'do', 'things', 'with', 'subpages', 'His', 'RfA', 'is', 'listed', 'on', 'NoSeptember', 'page', 'and', 'you', 'can', 'find', 'it', 'if', 'you', 'look', 'September', 'think', 'have', 'my', 'differences', 'with', 'El_C', 'to', 'be', 'sure', 'but', 'was', 'surprised', 'to', 'see', 'block', 'so', 'left', 'note', 'Not', 'at', 'all', 'you', 'are', 'making', 'straw', 'man', 'argument', 'here', 'never', 'claimed', 'Donohue', 'had', 'that', 'position', 'rather', 'that', 'practitioners', 'and', 'researchers', 'in', 'the', 'field', 'ignored', 'the', 'DSM', 'position', 'which', 'is', 'exactly', 'what', 'the', 'quote', 'says', 'and', 'also', 'something', 'Donohue', 'agrees', 'with', 'Again', 'was', 'combating', 'the', 'notion', 'that', 'it', 'was', 'absurd', 'part', 'to', 'claim', 'that', 'pedophilia', 'is', 'sexual', 'orientation', 'Since', 'many', 'researchers', 'hold', 'this', 'position', 'it', 'would', 'be', 'unfair', 'to', 'call', 'it', 'absurd', 'The', 'disorder', 'part', 'is', 'divided', 'in', 'the', 'field', 'some', 'argue', 'that', 'it', 'is', 'not', 'disorder', 'at', 'all', 'some', 'do', 'At', 'the', 'end', 'of', 'the', 'day', 'it', 'is', 'value', 'judgment', 'as', 'Cantor', 'pointed', 'out', 'earlier', 'in', 'the', 'thread', 'not', 'scientific', 'judgement', 'If', 'we', 'choose', 'to', 'make', 'this', 'value', 'judgment', 'in', 'the', 'article', 'it', 'should', 'be', 'stated', 'clearly', 'and', 'not', 'pretend', 'to', 'have', 'scientific', 'basis', 'Mainland', 'Asia', 'includes', 'the', 'lower', 'basin', 'of', 'China', 'Yangtze', 'River', 'as', 'well', 'as', 'Korea', 'But', 'being', 'specific', 'is', 'fine', 'too', 'just', 'found', 'citation', 'for', 'more', 'comprehensive', 'DNA', 'study', 'by', 'Hammer', 'below', 'rather', 'than', 'our', 'generarizations', 'and', 'speculation', 'so', 'far', 'Citation', 'for', 'Yayoi', 'culture', 'was', 'brought', 'to', 'Japan', 'by', 'migrants', 'from', 'Korea', 'who', 'in', 'turn', 'trace', 'their', 'roots', 'to', 'southeast', 'Asia', 'south', 'China', 'DNA', 'study', 'by', 'Hammer', 'Describes', 'the', 'Yayoi', 'migration', 'from', 'Korea', 'based', 'on', 'the', 'SRY', 'genes', 'and', 'other', 'genes', 'with', 'close', 'lineage', 'haplogroups', 'M122', 'and', 'M95', 'Reiterates', 'that', 'the', 'entire', 'haplogroup', 'has', 'been', 'proposed', 'to', 'have', 'Southeast', 'Asian', 'origin', 'Their', 'definition', 'of', 'Southeast', 'Asia', 'includes', 'southern', 'China', 'Then', 'hypothesizes', 'that', 'the', 'dispersals', 'of', 'Neolithic', 'farmers', 'from', 'Southeast', 'Asia', 'also', 'brought', 'haplogroup', 'lineages', 'to', 'Korea', 'and', 'eventually', 'to', 'Japan', 'In', 'the', 'concluding', 'paragraph', 'it', 'states', 'we', 'propose', 'that', 'the', 'Yayoi', 'chromosomes', 'descend', 'from', 'prehistoric', 'farmers', 'that', 'had', 'their', 'origins', 'in', 'southeastern', 'Asia', 'perhaps', 'going', 'back', 'to', 'the', 'origin', 'of', 'agriculture', 'in', 'this', 'region', 'Hammer', 'DNA', 'study', 'is', 'based', 'on', 'global', 'sample', 'consisted', 'of', 'males', 'from', 'Asian', 'populations', 'including', 'six', 'populations', 'sampled', 'from', 'across', 'the', 'Japanese', 'archipelago', 'pretty', 'much', 'everyone', 'from', 'warren', 'county', 'surrounding', 'regions', 'was', 'born', 'at', 'glens', 'falls', 'hospital', 'myself', 'included', 'however', 'not', 'sure', 'this', 'qualifies', 'anyone', 'as', 'being', 'glens', 'falls', 'native', 'rachel', 'ray', 'is', 'believe', 'actually', 'from', 'the', 'town', 'of', 'lake', 'luzerne', 'The', 'preceding', 'unsigned', 'comment', 'was', 'added', 'by', 'August', 'UTC', 'Hi', 'Explicit', 'can', 'you', 'block', 'Fenian', 'for', 'edit', 'warring', 'on', 'the', 'Giant', 'Causeway', 'wp', 'He', 'has', 'made', 'several', 'edits', 'which', 'can', 'only', 'be', 'described', 'as', 'terrorism', 'Notability', 'of', 'Rurika', 'Kasuga', 'tag', 'has', 'been', 'placed', 'on', 'Rurika', 'Kasuga', 'requesting', 'that', 'it', 'be', 'speedily', 'deleted', 'from', 'Wikipedia', 'This', 'has', 'been', 'done', 'because', 'the', 'article', 'seems', 'to', 'be', 'about', 'person', 'group', 'of', 'people', 'band', 'club', 'company', 'or', 'web', 'content', 'but', 'it', 'does', 'not', 'indicate', 'how', 'or', 'why', 'the', 'subject', 'is', 'notable', 'that', 'is', 'why', 'an', 'article', 'about', 'that', 'subject', 'should', 'be', 'included', 'in', 'Wikipedia', 'Under', 'the', 'criteria', 'for', 'speedy', 'deletion', 'articles', 'that', 'do', 'not', 'assert', 'notability', 'may', 'be', 'deleted', 'at', 'any', 'time', 'Please', 'see', 'the', 'guidelines', 'for', 'what', 'is', 'generally', 'accepted', 'as', 'notable', 'and', 'if', 'you', 'can', 'indicate', 'why', 'the', 'subject', 'of', 'this', 'article', 'is', 'notable', 'you', 'may', 'contest', 'the', 'tagging', 'To', 'do', 'this', 'add', 'on', 'the', 'top', 'of', 'the', 'page', 'below', 'the', 'existing', 'db', 'tag', 'and', 'leave', 'note', 'on', 'the', 'article', 'talk', 'page', 'explaining', 'your', 'position', 'Please', 'do', 'not', 'remove', 'the', 'speedy', 'deletion', 'tag', 'yourself', 'but', 'don', 'hesitate', 'to', 'add', 'information', 'to', 'the', 'article', 'that', 'would', 'confirm', 'its', 'subject', 'notability', 'under', 'the', 'guidelines', 'For', 'guidelines', 'on', 'specific', 'types', 'of', 'articles', 'you', 'may', 'want', 'to', 'check', 'out', 'our', 'criteria', 'for', 'biographies', 'for', 'web', 'sites', 'for', 'bands', 'or', 'for', 'companies', 'Feel', 'free', 'to', 'leave', 'note', 'on', 'my', 'talk', 'page', 'if', 'you', 'have', 'any', 'questions', 'about', 'this', 'Sure', 'but', 'the', 'lead', 'must', 'briefly', 'summarize', 'Armenia', 'history', 'simply', 'added', 'what', 'found', 'necessary', 'If', 'anyone', 'thinks', 'this', 'or', 'that', 'sentence', 'is', 'redundant', 'for', 'the', 'lead', 'they', 'are', 'welcome', 'to', 'remove', 'make', 'edits', 'talk', 'TFD', 'think', 'we', 'just', 'eced', 'think', 'we', 'responded', 'to', 'each', 'other', 'without', 'seeing', 'each', 'others', 'responses', 'added', 'something', 'in', 'response', 'to', 'yours', 'but', 'don', 'know', 'if', 'you', 'saw', 'mine', 'WP', 'CHICAGO', 'WP', 'FOUR', 'You', 'are', 'gay', 'or', 'antisemmitian', 'Archangel', 'WHite', 'Tiger', 'Meow', 'Greetingshhh', 'Uh', 'there', 'are', 'two', 'ways', 'why', 'you', 'do', 'erased', 'my', 'comment', 'about', 'WW2', 'that', 'holocaust', 'was', 'brutally', 'slaying', 'of', 'Jews', 'and', 'not', 'gays', 'Gypsys', 'Slavs', 'anyone', 'If', 'you', 'are', 'anti', 'semitian', 'than', 'shave', 'your', 'head', 'bald', 'and', 'go', 'to', 'the', 'skinhead', 'meetings', 'If', 'you', 'doubt', 'words', 'of', 'the', 'Bible', 'that', 'homosexuality', 'is', 'deadly', 'sin', 'make', 'pentagram', 'tatoo', 'on', 'your', 'forehead', 'go', 'to', 'the', 'satanistic', 'masses', 'with', 'your', 'gay', 'pals', 'First', 'and', 'last', 'warning', 'you', 'fucking', 'gay', 'won', 'appreciate', 'if', 'any', 'more', 'nazi', 'shwain', 'would', 'write', 'in', 'my', 'page', 'don', 'wish', 'to', 'talk', 'to', 'you', 'anymore', 'Beware', 'of', 'the', 'Dark', 'Side', 'FUCK', 'YOUR', 'FILTHY', 'MOTHER', 'IN', 'THE', 'ASS', 'DRY', 'Sorry', 'sorry', 'screwed', 'around', 'with', 'someones', 'talk', 'page', 'It', 'was', 'very', 'bad', 'to', 'do', 'know', 'how', 'having', 'the', 'templates', 'on', 'their', 'talk', 'page', 'helps', 'you', 'assert', 'your', 'dominance', 'over', 'them', 'know', 'should', 'bow', 'down', 'to', 'the', 'almighty', 'administrators', 'But', 'then', 'again', 'going', 'to', 'go', 'play', 'outside', 'with', 'your', 'mom', 'don', 'believe', 'the', 'Lisak', 'criticism', 'present', 'there', 'conforms', 'with', 'the', 'NPV', 'rule', 'Lisak', 'doesn', 'have', 'neutral', 'point', 'of', 'view', 'to', 'begin', 'with', 'If', 'an', 'offer', 'to', 'polygraph', 'or', 'even', 'concerned', 'review', 'of', 'polygraph', 'results', 'shocks', 'complainant', 'into', 'thinking', 'her', 'lies', 'have', 'been', 'uncovered', 'the', 'recantation', 'is', 'still', 'perfectly', 'valid', 'If', 'you', 'know', 'you', 'are', 'telling', 'the', 'truth', 'you', 'will', 'argue', 'with', 'machine', 'or', 'investigator', 'Also', 'part', 'of', 'Kanin', 'research', 'was', 'followup', 'of', 'the', 'recanted', 'story', 'where', 'possible', 'to', 'verify', 'if', 'any', 'were', 'false', 'recantations', 'In', 'all', 'followups', 'the', 'recanted', 'version', 'of', 'events', 'matched', 'what', 'the', 'accused', 'said', 'happened', 'Arguing', 'that', 'Lisak', 'is', 'respected', 'PHD', 'is', 'baseless', 'if', 'Kanin', 'is', 'respected', 'PHD', 'agree', 'that', 'my', 'edit', 'wasn', 'as', 'neutral', 'as', 'possible', 'though', 'so', 'apologize', 'for', 'that', 'Still', 'something', 'must', 'be', 'done', 'here', 'You', 'had', 'point', 'and', 'it', 'now', 'ammended', 'with', 'appropriate', 'encyclopedic', 'notability', 'significance', 'In', 'other', 'words', 'you', 're', 'too', 'lazy', 'to', 'actually', 'point', 'anything', 'out', 'Until', 'you', 'change', 'that', 'approach', 'the', 'tag', 'goes', 'As', 'for', 'your', 'claims', 'of', 'stalking', 'that', 'is', 'absolute', 'rubbish', 'and', 'serves', 'only', 'to', 'aggravate', 'the', 'situation', 'have', 'assumed', 'good', 'faith', 'and', 'good', 'intentions', 'on', 'your', 'part', 'and', 'have', 'never', 'suggested', 'or', 'seen', 'reason', 'to', 'suggest', 'that', 'you', 'might', 'have', 'some', 'ulterior', 'motive', 'in', 'mass', 'adding', 'links', 'to', 'one', 'specific', 'company', 'web', 'page', 'Nor', 'for', 'that', 'matter', 'have', 'ever', 'made', 'any', 'suggestion', 'that', 'this', 'is', 'an', 'administrative', 'matter', 'or', 'even', 'mentioned', 'such', 'role', 'Clearly', 'as', 'party', 'to', 'this', 'disagreement', 'would', 'not', 'do', 'so', 'at', 'any', 'rate', 'as', 'it', 'would', 'be', 'conflict', 'of', 'interest', 'would', 'ask', 'that', 'you', 'thus', 'extend', 'the', 'same', 'good', 'faith', 'toward', 'me', 'rather', 'than', 'making', 'spurious', 'and', 'unfounded', 'accusations', 'chatspy', 'Jmabel', 'in', 'regards', 'to', 'predominant', 'scholary', 'consensus', 'who', 'is', 'it', 'that', 'allegedly', 'claims', 'despite', 'Third', 'Way', 'rhetoric', 'fascism', 'in', 'power', 'functioned', 'rather', 'consistently', 'as', 'right', 'wing', 'force', 'As', 'far', 'as', 'aware', 'owning', 'numerous', 'books', 'on', 'the', 'subject', 'that', 'is', 'not', 'the', 'scholary', 'consensus', 'at', 'all', 'The', 'consensus', 'developed', 'by', 'respected', 'scholars', 'of', 'fascism', 'who', 'write', 'in', 'manner', 'which', 'is', 'not', 'bias', 'to', 'any', 'interest', 'group', 'such', 'as', 'Roger', 'Griffin', 'Hamish', 'McDonald', 'Roger', 'Eatwell', 'and', 'Zeev', 'Sternhell', 'all', 'recongise', 'fascism', 'as', 'Third', 'Way', 'as', 'the', 'references', 'show', 'The', 'only', 'dissenters', 'aware', 'of', 'who', 'seem', 'to', 'think', 'fascism', 'has', 'absoutely', 'no', 'leftist', 'connections', 'and', 'is', 'merely', 'radical', 'right', 'system', 'are', 'street', 'level', 'socialists', 'who', 'want', 'to', 'put', 'as', 'much', 'distance', 'between', 'the', 'movements', 'as', 'possible', 'This', 'of', 'course', 'does', 'not', 'come', 'from', 'educated', 'people', 'in', 'position', 'to', 'write', 'books', 'For', 'example', 'even', 'the', 'foremost', 'scholary', 'expert', 'on', 'Fascism', 'and', 'former', 'member', 'of', 'both', 'the', 'Communist', 'Party', 'and', 'then', 'Socialist', 'Party', 'of', 'Italy', 'Renzo', 'De', 'Felice', 'doesn', 'try', 'to', 'cover', 'up', 'its', 'socialistic', 'origins', 'and', 'third', 'way', 'status', 'This', 'is', 'man', 'who', 'has', 'wrote', 'definitive', 'seven', 'volume', 'piece', 'on', 'Mussolini']\n"
     ]
    }
   ],
   "source": [
    "# Call the List flatter\n",
    "flat_tokens = flatten(token_per_row)\n",
    "\n",
    "print(flat_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the stopwords\n",
    "# Already installed so will comment it out\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Need to remove stop words too\n",
    "# changing the stopwords from a list to a set (Performance Upgrade)\n",
    "ENGLISH_STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopword Removal\n",
    "Prior to removing stopwords, one has to change the case of the tokens (words) to be lowercase, which is also what is asked of us to do within the ToDo list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3291\n"
     ]
    }
   ],
   "source": [
    "# Changing all words into lowercase\n",
    "# Using a list comprehension to change it more efficienty\n",
    "# (They're better than for loops)\n",
    "flat_tokens = [token.lower() for token in flat_tokens]\n",
    "\n",
    "# Was 'Explanation', should be 'explanation'\n",
    "print(len(flat_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1762\n"
     ]
    }
   ],
   "source": [
    "# Actually removing stopwords\n",
    "stop_free = [token for token in flat_tokens if token not in ENGLISH_STOPWORDS]\n",
    "\n",
    "print(len(stop_free))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init Stemming"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
